{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-J9dvmz-JbK"
   },
   "source": [
    "# Deep Learning Frameworks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0btGdz3-Ptr"
   },
   "source": [
    "Great job on completing the neural network assignment! Well, we know the pain of working with neural networks from scratch. Don't fret! - because there are multiple frameworks, like Tensorflow, Keras, Pytorch, Caffe, etc. out there to help you build a deep learning model easily. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCxc_AeBAKDn"
   },
   "source": [
    "# Why Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLxkBRcMANHF"
   },
   "source": [
    "Keras is an open source deep learning framework for python. It is a high level API that is built upon Tensorflow. Keras makes deployment of neural networks really simple, with just a few lines of code! The syntax is clear, simple and intuitive.  We urge you to go through the documentation after this to get a better feel of Keras. The link is: https://keras.io/api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GRWp2rrp2AK"
   },
   "source": [
    "#Importing Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K25nLJeRIFSL"
   },
   "source": [
    "We will first import tensorflow. Note that Keras uses Tensorflow 2.  as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_U64Pp7IOae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sq6aaZ0dEJTL"
   },
   "source": [
    "# The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTLfzHLFENcN"
   },
   "source": [
    "We will geenerate a random n-class classification problem using scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "in3X10QhEYM1",
    "outputId": "0a5e9ab3-8374-41ce-991d-92a6fd3edd59",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(5000, 10) (5000,)\n"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "#X, y = make_classification(n_samples=3000, n_informative = 4, n_features=10, n_classes=5, random_state=1)\n",
    "\n",
    "X,y =make_classification(n_samples=5000, n_informative = 8, n_features=10, n_redundant = 0, n_classes=5, random_state=1)\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Wr9zs4cFjac"
   },
   "source": [
    "We have created a dataset with m=1000 and n=10. Each training example belongs to one of 5 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1bX3RwKFuOJ"
   },
   "source": [
    "# Split and standardization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RO8Os900Fycy"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)   #Split data into 70% training, 30%test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2Xr0fLiGHh_"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler    #Standardize data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EfJImjfMZmzO"
   },
   "source": [
    "# Converting the labels to one hot encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kjeXHOMcZrM1"
   },
   "source": [
    "To convert our targets into a one hot encoding we use the Keras to_categorical function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dtx2XYc_Z39t"
   },
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYyCI_EFHJo0"
   },
   "source": [
    "# **MAKING THE NEURAL NETWORK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8r3ox244Thad"
   },
   "source": [
    "##The Sequential class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJx4JnoqHgEy"
   },
   "source": [
    "The keras.models.Sequential class is a wrapper for the neural network model that treats the network as a sequence of layers. We assign it to a variable model.  Click [here](https://keras.io/api/models/sequential/) to check out the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X836dVLpIVB4"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N93HlSc1T1Jp"
   },
   "source": [
    "##The Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Aa-YdXEJJio"
   },
   "source": [
    "First, we call the Input() object of Keras, to instantiate a Keras tensor. Note that we only input the number of features and not the training size. So the shape argument of the Input() object is inputs (n, None) \n",
    "\n",
    "To add a certain object or layer to the Sequential model, we use the *add* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGWqM_HiJrRX"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.Input(shape=10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2gEqpjJUI2X"
   },
   "source": [
    "##Adding layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELKmipHsKUTo"
   },
   "source": [
    "To add a layer to a neural network, we add a dense layer, or the Dense class. Arguments to the Dense class include the number of neurons for the layer, the activation, regularizer and and other stuff which we do not need to worry about. \n",
    "\n",
    "In this model we will make an NN with 2 hidden layers, each activated by the relu function. The last layer , which is the output layer, has 5 neurons(one belonging to each class), activated by the softmax function. \n",
    "\n",
    "[Dense layer documentation link](https://keras.io/api/layers/core_layers/dense/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJBbxgEALDsT"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=30, activation='relu', )) #First hidden layer with 30 neurons, relu activation\n",
    "model.add(tf.keras.layers.Dense(units=15, activation='relu')) #Second hidden layer with 15 neurons, relu activation\n",
    "model.add(tf.keras.layers.Dense(units=5, activation='softmax')) #Output layer with 5 neuron, softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGnQ4HLEWm3M"
   },
   "source": [
    "##Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rli-9UekVftL"
   },
   "source": [
    "Note: Here we pass the type of activation as an argument to the Dense class. This is the same as adding an Activation layer with the activation inside it. So the first line of code above is the same as:\n",
    "\n",
    "\n",
    "```\n",
    "model.add(tf.keras.layers.Dense(64))\n",
    "model.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gr8wmFs1W8FG"
   },
   "source": [
    "Click [here](https://keras.io/api/layers/activations/) to check out the various activations provided by keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fDJy4tpfXIZi"
   },
   "source": [
    "##Model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNv3zOtWLjvO"
   },
   "source": [
    "Just that many lines of code to prototype our neural network model! Simple right? We can check out the model's details by calling the summary() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "4T6Pa9FbLuBU",
    "outputId": "ebfd9db4-171b-4bb7-feb1-c0f573111b51",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 30)                330       \n_________________________________________________________________\ndense_1 (Dense)              (None, 15)                465       \n_________________________________________________________________\ndense_2 (Dense)              (None, 5)                 80        \n=================================================================\nTotal params: 875\nTrainable params: 875\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsMp9jtxXgFB"
   },
   "source": [
    "## The compile() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLmun9IpL7Ip"
   },
   "source": [
    "Next, we compile the model using the compile() method. Here we mention what our loss function should be, the type of optimizer used, and what metrics to print.\n",
    "\n",
    "We will be using the categorical cross-entropy as our loss function, with the adam optimizer and accuracy as our metric. Note that we pass our metrics as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMZ7TEqTMPns"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gzogFygcX0ED"
   },
   "source": [
    "## Keras Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaQ6H21PX3Dz"
   },
   "source": [
    "Passing optimizer='adam' to the compile method uses the default learning rate and some other parameters. But often , we want to choose the learning rate, momentum, etc. So, we call the optimizer's class, store it in a variable and pass it as an argument to the compile method.\n",
    "\n",
    "For example, if we want to use stochastic gradient descent with a learning rate of 0.1 and momentum 0.9 , we would code it as follows:\n",
    "\n",
    "\n",
    "```\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer =opt, metrics=['accuracy'])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yBmwz-qBZOV_"
   },
   "source": [
    "Click [here](https://keras.io/api/optimizers/) to check out the various Keras optimizers and their syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4kyDJpKAZY3a"
   },
   "source": [
    "## The fit() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R2zNL_SGNL2V"
   },
   "source": [
    "Finally , we call the fit() function to fit our data! Keras takes care of all the mathematical computation of forward prop and backprop! The fit() function takes into input the data, true labels, batch size in which we train, the number of epochs, and the validation data(here which is our test set). It returns a Keras history object which contains various attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Yx8qroZnNxjc",
    "outputId": "ca52c3a0-3b7f-42e4-bbd5-2aad61bb75f6",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===] - 1s 150us/sample - loss: 0.3062 - accuracy: 0.8966 - val_loss: 0.4325 - val_accuracy: 0.8460\nEpoch 69/200\n3500/3500 [==============================] - 0s 141us/sample - loss: 0.3069 - accuracy: 0.8994 - val_loss: 0.4331 - val_accuracy: 0.8453\nEpoch 70/200\n3500/3500 [==============================] - 1s 143us/sample - loss: 0.3063 - accuracy: 0.8986 - val_loss: 0.4296 - val_accuracy: 0.8453\nEpoch 71/200\n3500/3500 [==============================] - 0s 131us/sample - loss: 0.3034 - accuracy: 0.9017 - val_loss: 0.4330 - val_accuracy: 0.8440\nEpoch 72/200\n3500/3500 [==============================] - 1s 198us/sample - loss: 0.3006 - accuracy: 0.8991 - val_loss: 0.4314 - val_accuracy: 0.8453\nEpoch 73/200\n3500/3500 [==============================] - 1s 170us/sample - loss: 0.3007 - accuracy: 0.8977 - val_loss: 0.4298 - val_accuracy: 0.8460\nEpoch 74/200\n3500/3500 [==============================] - 1s 175us/sample - loss: 0.2991 - accuracy: 0.9000 - val_loss: 0.4339 - val_accuracy: 0.8480\nEpoch 75/200\n3500/3500 [==============================] - 1s 202us/sample - loss: 0.2957 - accuracy: 0.9023 - val_loss: 0.4341 - val_accuracy: 0.8453\nEpoch 76/200\n3500/3500 [==============================] - 1s 196us/sample - loss: 0.2969 - accuracy: 0.9051 - val_loss: 0.4339 - val_accuracy: 0.8467\nEpoch 77/200\n3500/3500 [==============================] - 1s 195us/sample - loss: 0.2961 - accuracy: 0.9040 - val_loss: 0.4356 - val_accuracy: 0.8453\nEpoch 78/200\n3500/3500 [==============================] - 1s 170us/sample - loss: 0.2937 - accuracy: 0.9020 - val_loss: 0.4266 - val_accuracy: 0.8500\nEpoch 79/200\n3500/3500 [==============================] - 1s 175us/sample - loss: 0.2927 - accuracy: 0.9029 - val_loss: 0.4253 - val_accuracy: 0.8480\nEpoch 80/200\n3500/3500 [==============================] - 1s 207us/sample - loss: 0.2907 - accuracy: 0.9060 - val_loss: 0.4391 - val_accuracy: 0.8500\nEpoch 81/200\n3500/3500 [==============================] - 1s 172us/sample - loss: 0.2907 - accuracy: 0.9046 - val_loss: 0.4427 - val_accuracy: 0.8427\nEpoch 82/200\n3500/3500 [==============================] - 1s 194us/sample - loss: 0.2891 - accuracy: 0.9043 - val_loss: 0.4439 - val_accuracy: 0.8440\nEpoch 83/200\n3500/3500 [==============================] - 1s 258us/sample - loss: 0.2872 - accuracy: 0.9063 - val_loss: 0.4276 - val_accuracy: 0.8453\nEpoch 84/200\n3500/3500 [==============================] - 1s 314us/sample - loss: 0.2906 - accuracy: 0.9063 - val_loss: 0.4312 - val_accuracy: 0.8480\nEpoch 85/200\n3500/3500 [==============================] - 1s 226us/sample - loss: 0.2866 - accuracy: 0.9043 - val_loss: 0.4361 - val_accuracy: 0.8500\nEpoch 86/200\n3500/3500 [==============================] - 1s 207us/sample - loss: 0.2859 - accuracy: 0.9069 - val_loss: 0.4305 - val_accuracy: 0.8500\nEpoch 87/200\n3500/3500 [==============================] - 1s 217us/sample - loss: 0.2845 - accuracy: 0.9037 - val_loss: 0.4304 - val_accuracy: 0.8540\nEpoch 88/200\n3500/3500 [==============================] - 1s 209us/sample - loss: 0.2824 - accuracy: 0.9074 - val_loss: 0.4313 - val_accuracy: 0.8520\nEpoch 89/200\n3500/3500 [==============================] - 1s 216us/sample - loss: 0.2818 - accuracy: 0.9049 - val_loss: 0.4370 - val_accuracy: 0.8480\nEpoch 90/200\n3500/3500 [==============================] - 1s 264us/sample - loss: 0.2810 - accuracy: 0.9071 - val_loss: 0.4322 - val_accuracy: 0.8427\nEpoch 91/200\n3500/3500 [==============================] - 1s 233us/sample - loss: 0.2801 - accuracy: 0.9077 - val_loss: 0.4369 - val_accuracy: 0.8547\nEpoch 92/200\n3500/3500 [==============================] - 1s 209us/sample - loss: 0.2786 - accuracy: 0.9080 - val_loss: 0.4338 - val_accuracy: 0.8533\nEpoch 93/200\n3500/3500 [==============================] - 1s 196us/sample - loss: 0.2764 - accuracy: 0.9100 - val_loss: 0.4394 - val_accuracy: 0.8487\nEpoch 94/200\n3500/3500 [==============================] - 1s 192us/sample - loss: 0.2766 - accuracy: 0.9051 - val_loss: 0.4350 - val_accuracy: 0.8527\nEpoch 95/200\n3500/3500 [==============================] - 1s 185us/sample - loss: 0.2760 - accuracy: 0.9091 - val_loss: 0.4365 - val_accuracy: 0.8533\nEpoch 96/200\n3500/3500 [==============================] - 1s 202us/sample - loss: 0.2739 - accuracy: 0.9074 - val_loss: 0.4285 - val_accuracy: 0.8547\nEpoch 97/200\n3500/3500 [==============================] - 1s 164us/sample - loss: 0.2739 - accuracy: 0.9091 - val_loss: 0.4416 - val_accuracy: 0.8493\nEpoch 98/200\n3500/3500 [==============================] - 1s 160us/sample - loss: 0.2721 - accuracy: 0.9106 - val_loss: 0.4334 - val_accuracy: 0.8540\nEpoch 99/200\n3500/3500 [==============================] - 1s 152us/sample - loss: 0.2706 - accuracy: 0.9111 - val_loss: 0.4458 - val_accuracy: 0.8513\nEpoch 100/200\n3500/3500 [==============================] - 1s 150us/sample - loss: 0.2699 - accuracy: 0.9149 - val_loss: 0.4413 - val_accuracy: 0.8513\nEpoch 101/200\n3500/3500 [==============================] - 0s 141us/sample - loss: 0.2680 - accuracy: 0.9111 - val_loss: 0.4369 - val_accuracy: 0.8527\nEpoch 102/200\n3500/3500 [==============================] - 0s 142us/sample - loss: 0.2661 - accuracy: 0.9117 - val_loss: 0.4327 - val_accuracy: 0.8547\nEpoch 103/200\n3500/3500 [==============================] - 1s 145us/sample - loss: 0.2667 - accuracy: 0.9094 - val_loss: 0.4332 - val_accuracy: 0.8600\nEpoch 104/200\n3500/3500 [==============================] - 1s 149us/sample - loss: 0.2644 - accuracy: 0.9123 - val_loss: 0.4384 - val_accuracy: 0.8553\nEpoch 105/200\n3500/3500 [==============================] - 1s 153us/sample - loss: 0.2662 - accuracy: 0.9109 - val_loss: 0.4417 - val_accuracy: 0.8573\nEpoch 106/200\n3500/3500 [==============================] - 1s 151us/sample - loss: 0.2635 - accuracy: 0.9103 - val_loss: 0.4370 - val_accuracy: 0.8607\nEpoch 107/200\n3500/3500 [==============================] - 1s 143us/sample - loss: 0.2639 - accuracy: 0.9111 - val_loss: 0.4310 - val_accuracy: 0.8593\nEpoch 108/200\n3500/3500 [==============================] - 1s 174us/sample - loss: 0.2603 - accuracy: 0.9126 - val_loss: 0.4354 - val_accuracy: 0.8513\nEpoch 109/200\n3500/3500 [==============================] - 1s 167us/sample - loss: 0.2594 - accuracy: 0.9186 - val_loss: 0.4596 - val_accuracy: 0.8453\nEpoch 110/200\n3500/3500 [==============================] - 1s 159us/sample - loss: 0.2606 - accuracy: 0.9154 - val_loss: 0.4465 - val_accuracy: 0.8560\nEpoch 111/200\n3500/3500 [==============================] - 1s 161us/sample - loss: 0.2600 - accuracy: 0.9149 - val_loss: 0.4410 - val_accuracy: 0.8533\nEpoch 112/200\n3500/3500 [==============================] - 1s 150us/sample - loss: 0.2614 - accuracy: 0.9089 - val_loss: 0.4477 - val_accuracy: 0.8507\nEpoch 113/200\n3500/3500 [==============================] - 1s 170us/sample - loss: 0.2590 - accuracy: 0.9154 - val_loss: 0.4415 - val_accuracy: 0.8613\nEpoch 114/200\n3500/3500 [==============================] - 1s 155us/sample - loss: 0.2596 - accuracy: 0.9131 - val_loss: 0.4408 - val_accuracy: 0.8600\nEpoch 115/200\n3500/3500 [==============================] - 1s 144us/sample - loss: 0.2569 - accuracy: 0.9140 - val_loss: 0.4345 - val_accuracy: 0.8547\nEpoch 116/200\n3500/3500 [==============================] - 0s 128us/sample - loss: 0.2553 - accuracy: 0.9154 - val_loss: 0.4395 - val_accuracy: 0.8527\nEpoch 117/200\n3500/3500 [==============================] - 1s 169us/sample - loss: 0.2557 - accuracy: 0.9120 - val_loss: 0.4439 - val_accuracy: 0.8580\nEpoch 118/200\n3500/3500 [==============================] - 0s 134us/sample - loss: 0.2544 - accuracy: 0.9166 - val_loss: 0.4453 - val_accuracy: 0.8540\nEpoch 119/200\n3500/3500 [==============================] - 0s 143us/sample - loss: 0.2501 - accuracy: 0.9160 - val_loss: 0.4530 - val_accuracy: 0.8527\nEpoch 120/200\n3500/3500 [==============================] - 0s 130us/sample - loss: 0.2525 - accuracy: 0.9160 - val_loss: 0.4454 - val_accuracy: 0.8560\nEpoch 121/200\n3500/3500 [==============================] - 0s 137us/sample - loss: 0.2493 - accuracy: 0.9177 - val_loss: 0.4393 - val_accuracy: 0.8560\nEpoch 122/200\n3500/3500 [==============================] - 1s 152us/sample - loss: 0.2522 - accuracy: 0.9146 - val_loss: 0.4420 - val_accuracy: 0.8567\nEpoch 123/200\n3500/3500 [==============================] - 0s 137us/sample - loss: 0.2518 - accuracy: 0.9143 - val_loss: 0.4403 - val_accuracy: 0.8533\nEpoch 124/200\n3500/3500 [==============================] - 1s 149us/sample - loss: 0.2462 - accuracy: 0.9163 - val_loss: 0.4464 - val_accuracy: 0.8560\nEpoch 125/200\n3500/3500 [==============================] - 0s 142us/sample - loss: 0.2473 - accuracy: 0.9169 - val_loss: 0.4422 - val_accuracy: 0.8560\nEpoch 126/200\n3500/3500 [==============================] - 0s 134us/sample - loss: 0.2464 - accuracy: 0.9169 - val_loss: 0.4531 - val_accuracy: 0.8540\nEpoch 127/200\n3500/3500 [==============================] - 0s 139us/sample - loss: 0.2470 - accuracy: 0.9169 - val_loss: 0.4461 - val_accuracy: 0.8553\nEpoch 128/200\n3500/3500 [==============================] - 0s 130us/sample - loss: 0.2464 - accuracy: 0.9191 - val_loss: 0.4489 - val_accuracy: 0.8567\nEpoch 129/200\n3500/3500 [==============================] - 1s 146us/sample - loss: 0.2443 - accuracy: 0.9154 - val_loss: 0.4460 - val_accuracy: 0.8600\nEpoch 130/200\n3500/3500 [==============================] - 0s 130us/sample - loss: 0.2447 - accuracy: 0.9163 - val_loss: 0.4470 - val_accuracy: 0.8560\nEpoch 131/200\n3500/3500 [==============================] - 0s 141us/sample - loss: 0.2448 - accuracy: 0.9177 - val_loss: 0.4429 - val_accuracy: 0.8600\nEpoch 132/200\n3500/3500 [==============================] - 0s 143us/sample - loss: 0.2443 - accuracy: 0.9171 - val_loss: 0.4389 - val_accuracy: 0.8593\nEpoch 133/200\n3500/3500 [==============================] - 1s 147us/sample - loss: 0.2421 - accuracy: 0.9149 - val_loss: 0.4485 - val_accuracy: 0.8593\nEpoch 134/200\n3500/3500 [==============================] - 1s 170us/sample - loss: 0.2427 - accuracy: 0.9166 - val_loss: 0.4461 - val_accuracy: 0.8580\nEpoch 135/200\n3500/3500 [==============================] - 1s 183us/sample - loss: 0.2426 - accuracy: 0.9191 - val_loss: 0.4502 - val_accuracy: 0.8593\nEpoch 136/200\n3500/3500 [==============================] - 1s 149us/sample - loss: 0.2407 - accuracy: 0.9186 - val_loss: 0.4468 - val_accuracy: 0.8553\nEpoch 137/200\n3500/3500 [==============================] - 1s 159us/sample - loss: 0.2406 - accuracy: 0.9163 - val_loss: 0.4533 - val_accuracy: 0.8553\nEpoch 138/200\n3500/3500 [==============================] - 1s 177us/sample - loss: 0.2390 - accuracy: 0.9189 - val_loss: 0.4541 - val_accuracy: 0.8553\nEpoch 139/200\n3500/3500 [==============================] - 1s 212us/sample - loss: 0.2393 - accuracy: 0.9180 - val_loss: 0.4479 - val_accuracy: 0.8573\nEpoch 140/200\n3500/3500 [==============================] - 1s 213us/sample - loss: 0.2380 - accuracy: 0.9197 - val_loss: 0.4490 - val_accuracy: 0.8600\nEpoch 141/200\n3500/3500 [==============================] - 1s 226us/sample - loss: 0.2378 - accuracy: 0.9209 - val_loss: 0.4485 - val_accuracy: 0.8573\nEpoch 142/200\n3500/3500 [==============================] - 1s 274us/sample - loss: 0.2352 - accuracy: 0.9194 - val_loss: 0.4525 - val_accuracy: 0.8533\nEpoch 143/200\n3500/3500 [==============================] - 1s 244us/sample - loss: 0.2350 - accuracy: 0.9209 - val_loss: 0.4478 - val_accuracy: 0.8647\nEpoch 144/200\n3500/3500 [==============================] - 1s 210us/sample - loss: 0.2357 - accuracy: 0.9211 - val_loss: 0.4540 - val_accuracy: 0.8547\nEpoch 145/200\n3500/3500 [==============================] - 1s 206us/sample - loss: 0.2355 - accuracy: 0.9209 - val_loss: 0.4533 - val_accuracy: 0.8580\nEpoch 146/200\n3500/3500 [==============================] - 1s 177us/sample - loss: 0.2339 - accuracy: 0.9200 - val_loss: 0.4534 - val_accuracy: 0.8533\nEpoch 147/200\n3500/3500 [==============================] - 1s 150us/sample - loss: 0.2330 - accuracy: 0.9226 - val_loss: 0.4605 - val_accuracy: 0.8587\nEpoch 148/200\n3500/3500 [==============================] - 1s 143us/sample - loss: 0.2324 - accuracy: 0.9200 - val_loss: 0.4477 - val_accuracy: 0.8593\nEpoch 149/200\n3500/3500 [==============================] - 1s 169us/sample - loss: 0.2301 - accuracy: 0.9237 - val_loss: 0.4575 - val_accuracy: 0.8580\nEpoch 150/200\n3500/3500 [==============================] - 1s 284us/sample - loss: 0.2313 - accuracy: 0.9226 - val_loss: 0.4630 - val_accuracy: 0.8533\nEpoch 151/200\n3500/3500 [==============================] - 1s 290us/sample - loss: 0.2296 - accuracy: 0.9226 - val_loss: 0.4619 - val_accuracy: 0.8587\nEpoch 152/200\n3500/3500 [==============================] - 1s 266us/sample - loss: 0.2290 - accuracy: 0.9226 - val_loss: 0.4530 - val_accuracy: 0.8520\nEpoch 153/200\n3500/3500 [==============================] - 1s 239us/sample - loss: 0.2307 - accuracy: 0.9217 - val_loss: 0.4605 - val_accuracy: 0.8573\nEpoch 154/200\n3500/3500 [==============================] - 1s 146us/sample - loss: 0.2283 - accuracy: 0.9231 - val_loss: 0.4651 - val_accuracy: 0.8500\nEpoch 155/200\n3500/3500 [==============================] - 1s 147us/sample - loss: 0.2264 - accuracy: 0.9257 - val_loss: 0.4538 - val_accuracy: 0.8553\nEpoch 156/200\n3500/3500 [==============================] - 1s 145us/sample - loss: 0.2274 - accuracy: 0.9234 - val_loss: 0.4629 - val_accuracy: 0.8607\nEpoch 157/200\n3500/3500 [==============================] - 1s 146us/sample - loss: 0.2268 - accuracy: 0.9249 - val_loss: 0.4631 - val_accuracy: 0.8553\nEpoch 158/200\n3500/3500 [==============================] - 1s 254us/sample - loss: 0.2240 - accuracy: 0.9226 - val_loss: 0.4627 - val_accuracy: 0.8560\nEpoch 159/200\n3500/3500 [==============================] - 1s 186us/sample - loss: 0.2252 - accuracy: 0.9266 - val_loss: 0.4566 - val_accuracy: 0.8587\nEpoch 160/200\n3500/3500 [==============================] - 1s 174us/sample - loss: 0.2231 - accuracy: 0.9251 - val_loss: 0.4624 - val_accuracy: 0.8547\nEpoch 161/200\n3500/3500 [==============================] - 1s 189us/sample - loss: 0.2267 - accuracy: 0.9240 - val_loss: 0.4612 - val_accuracy: 0.8553\nEpoch 162/200\n3500/3500 [==============================] - 1s 172us/sample - loss: 0.2249 - accuracy: 0.9240 - val_loss: 0.4759 - val_accuracy: 0.8527\nEpoch 163/200\n3500/3500 [==============================] - 1s 173us/sample - loss: 0.2223 - accuracy: 0.9251 - val_loss: 0.4531 - val_accuracy: 0.8560\nEpoch 164/200\n3500/3500 [==============================] - 1s 183us/sample - loss: 0.2210 - accuracy: 0.9286 - val_loss: 0.4613 - val_accuracy: 0.8540\nEpoch 165/200\n3500/3500 [==============================] - 1s 172us/sample - loss: 0.2211 - accuracy: 0.9280 - val_loss: 0.4766 - val_accuracy: 0.8560\nEpoch 166/200\n3500/3500 [==============================] - 1s 166us/sample - loss: 0.2208 - accuracy: 0.9280 - val_loss: 0.4590 - val_accuracy: 0.8500\nEpoch 167/200\n3500/3500 [==============================] - 1s 228us/sample - loss: 0.2183 - accuracy: 0.9269 - val_loss: 0.4548 - val_accuracy: 0.8547\nEpoch 168/200\n3500/3500 [==============================] - 1s 250us/sample - loss: 0.2208 - accuracy: 0.9251 - val_loss: 0.4577 - val_accuracy: 0.8567\nEpoch 169/200\n3500/3500 [==============================] - 1s 193us/sample - loss: 0.2163 - accuracy: 0.9266 - val_loss: 0.4792 - val_accuracy: 0.8473\nEpoch 170/200\n3500/3500 [==============================] - 1s 195us/sample - loss: 0.2170 - accuracy: 0.9317 - val_loss: 0.4580 - val_accuracy: 0.8573\nEpoch 171/200\n3500/3500 [==============================] - 1s 182us/sample - loss: 0.2158 - accuracy: 0.9269 - val_loss: 0.4717 - val_accuracy: 0.8533\nEpoch 172/200\n3500/3500 [==============================] - 0s 136us/sample - loss: 0.2180 - accuracy: 0.9251 - val_loss: 0.4569 - val_accuracy: 0.8527\nEpoch 173/200\n3500/3500 [==============================] - 1s 158us/sample - loss: 0.2145 - accuracy: 0.9291 - val_loss: 0.4555 - val_accuracy: 0.8587\nEpoch 174/200\n3500/3500 [==============================] - 1s 163us/sample - loss: 0.2141 - accuracy: 0.9274 - val_loss: 0.4573 - val_accuracy: 0.8593\nEpoch 175/200\n3500/3500 [==============================] - 1s 165us/sample - loss: 0.2134 - accuracy: 0.9286 - val_loss: 0.4703 - val_accuracy: 0.8547\nEpoch 176/200\n3500/3500 [==============================] - 1s 193us/sample - loss: 0.2148 - accuracy: 0.9277 - val_loss: 0.4701 - val_accuracy: 0.8573\nEpoch 177/200\n3500/3500 [==============================] - 1s 194us/sample - loss: 0.2112 - accuracy: 0.9314 - val_loss: 0.4832 - val_accuracy: 0.8553\nEpoch 178/200\n3500/3500 [==============================] - 0s 143us/sample - loss: 0.2138 - accuracy: 0.9280 - val_loss: 0.4599 - val_accuracy: 0.8593\nEpoch 179/200\n3500/3500 [==============================] - 0s 141us/sample - loss: 0.2122 - accuracy: 0.9337 - val_loss: 0.4625 - val_accuracy: 0.8587\nEpoch 180/200\n3500/3500 [==============================] - 1s 148us/sample - loss: 0.2145 - accuracy: 0.9217 - val_loss: 0.4707 - val_accuracy: 0.8560\nEpoch 181/200\n3500/3500 [==============================] - 0s 134us/sample - loss: 0.2101 - accuracy: 0.9289 - val_loss: 0.4581 - val_accuracy: 0.8540\nEpoch 182/200\n3500/3500 [==============================] - 1s 156us/sample - loss: 0.2114 - accuracy: 0.9326 - val_loss: 0.4732 - val_accuracy: 0.8593\nEpoch 183/200\n3500/3500 [==============================] - 1s 152us/sample - loss: 0.2105 - accuracy: 0.9280 - val_loss: 0.4661 - val_accuracy: 0.8573\nEpoch 184/200\n3500/3500 [==============================] - 1s 160us/sample - loss: 0.2121 - accuracy: 0.9283 - val_loss: 0.4606 - val_accuracy: 0.8547\nEpoch 185/200\n3500/3500 [==============================] - 1s 150us/sample - loss: 0.2077 - accuracy: 0.9297 - val_loss: 0.4719 - val_accuracy: 0.8560\nEpoch 186/200\n3500/3500 [==============================] - 1s 151us/sample - loss: 0.2075 - accuracy: 0.9303 - val_loss: 0.4735 - val_accuracy: 0.8573\nEpoch 187/200\n3500/3500 [==============================] - 0s 137us/sample - loss: 0.2073 - accuracy: 0.9300 - val_loss: 0.4805 - val_accuracy: 0.8513\nEpoch 188/200\n3500/3500 [==============================] - 0s 142us/sample - loss: 0.2056 - accuracy: 0.9329 - val_loss: 0.4656 - val_accuracy: 0.8580\nEpoch 189/200\n3500/3500 [==============================] - 1s 151us/sample - loss: 0.2040 - accuracy: 0.9329 - val_loss: 0.4691 - val_accuracy: 0.8627\nEpoch 190/200\n3500/3500 [==============================] - 0s 142us/sample - loss: 0.2067 - accuracy: 0.9303 - val_loss: 0.4867 - val_accuracy: 0.8487\nEpoch 191/200\n3500/3500 [==============================] - 1s 155us/sample - loss: 0.2035 - accuracy: 0.9354 - val_loss: 0.4736 - val_accuracy: 0.8553\nEpoch 192/200\n3500/3500 [==============================] - 1s 148us/sample - loss: 0.2061 - accuracy: 0.9306 - val_loss: 0.4777 - val_accuracy: 0.8567\nEpoch 193/200\n3500/3500 [==============================] - 1s 145us/sample - loss: 0.2050 - accuracy: 0.9346 - val_loss: 0.4687 - val_accuracy: 0.8587\nEpoch 194/200\n3500/3500 [==============================] - 0s 139us/sample - loss: 0.2035 - accuracy: 0.9294 - val_loss: 0.4787 - val_accuracy: 0.8533\nEpoch 195/200\n3500/3500 [==============================] - 1s 152us/sample - loss: 0.2021 - accuracy: 0.9317 - val_loss: 0.4741 - val_accuracy: 0.8500\nEpoch 196/200\n3500/3500 [==============================] - 0s 139us/sample - loss: 0.2041 - accuracy: 0.9329 - val_loss: 0.4796 - val_accuracy: 0.8513\nEpoch 197/200\n3500/3500 [==============================] - 1s 234us/sample - loss: 0.2018 - accuracy: 0.9311 - val_loss: 0.4704 - val_accuracy: 0.8533\nEpoch 198/200\n3500/3500 [==============================] - 0s 142us/sample - loss: 0.2044 - accuracy: 0.9334 - val_loss: 0.4735 - val_accuracy: 0.8600\nEpoch 199/200\n3500/3500 [==============================] - 1s 231us/sample - loss: 0.2025 - accuracy: 0.9334 - val_loss: 0.4822 - val_accuracy: 0.8587\nEpoch 200/200\n3500/3500 [==============================] - 1s 200us/sample - loss: 0.1992 - accuracy: 0.9334 - val_loss: 0.4792 - val_accuracy: 0.8513\n"
    }
   ],
   "source": [
    "keras_history = model.fit(X_train, y_train , batch_size=16, epochs=200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rUkigFLQcAfL"
   },
   "source": [
    "##The Keras History Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJRNfnw6cGaT"
   },
   "source": [
    "The Keras history object has two main attributes- \n",
    "\n",
    "1)model \n",
    "\n",
    "2)history\n",
    "\n",
    "The model contains all information about the weights, inputs, activations and so on\n",
    "\n",
    "For example, to get the weights you would code:\n",
    "\n",
    "\n",
    "```\n",
    "keras_history.model.get_weights()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1AnMOSFhg20"
   },
   "source": [
    "The history is a dictionary containing training loss, training accuracy, validation loss, validation accuracy, etc. after each epoch. Each key contains an array of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vBUz_lDQh2y1",
    "outputId": "1231a5e6-58ca-4527-fa2f-000a6e648c74"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "keras_history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4vq5LXY1iyfU"
   },
   "source": [
    "## Post training analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwQOaGb2jCPX"
   },
   "source": [
    "Now we plot the training and test loss with each epoch. A key observation to make is that our model is overfitting- training accuracy is 94% while test accuracy is 87%. Notice how the training loss decreases while the test loss increases after a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "qMSG1xPvOAoI",
    "outputId": "9745afe7-ac6f-4cfa-e0af-4c3ab57f18eb"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x177e448ecc0>"
     },
     "metadata": {},
     "execution_count": 13
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 385.78125 262.19625\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 262.19625 \r\nL 385.78125 262.19625 \r\nL 385.78125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 43.78125 224.64 \r\nL 378.58125 224.64 \r\nL 378.58125 7.2 \r\nL 43.78125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"md5feed0369\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#md5feed0369\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(55.818182 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"97.23607\" xlink:href=\"#md5feed0369\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 25 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(90.87357 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"135.472707\" xlink:href=\"#md5feed0369\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(129.110207 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"173.709345\" xlink:href=\"#md5feed0369\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 75 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(167.346845 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"211.945983\" xlink:href=\"#md5feed0369\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 100 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(202.402233 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"250.18262\" xlink:href=\"#md5feed0369\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 125 -->\r\n      <g transform=\"translate(240.63887 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"288.419258\" xlink:href=\"#md5feed0369\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 150 -->\r\n      <g transform=\"translate(278.875508 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"326.655896\" xlink:href=\"#md5feed0369\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 175 -->\r\n      <g transform=\"translate(317.112146 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"364.892534\" xlink:href=\"#md5feed0369\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(355.348784 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_10\">\r\n     <!-- Epoch -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n      <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n     </defs>\r\n     <g transform=\"translate(195.870313 252.916562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_10\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m97afb06e02\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m97afb06e02\" y=\"214.626643\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.2 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 218.425861)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m97afb06e02\" y=\"182.690616\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 186.489835)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m97afb06e02\" y=\"150.754589\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 154.553808)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m97afb06e02\" y=\"118.818562\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 122.617781)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m97afb06e02\" y=\"86.882536\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(20.878125 90.681754)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m97afb06e02\" y=\"54.946509\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 1.2 -->\r\n      <g transform=\"translate(20.878125 58.745728)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m97afb06e02\" y=\"23.010482\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 1.4 -->\r\n      <g transform=\"translate(20.878125 26.809701)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_18\">\r\n     <!-- Loss -->\r\n     <defs>\r\n      <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798438 126.887187)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p5b623d9b55)\" d=\"M 58.999432 17.083636 \r\nL 60.528897 79.252417 \r\nL 62.058363 105.586488 \r\nL 63.587828 119.774127 \r\nL 65.117294 130.788541 \r\nL 66.646759 139.060479 \r\nL 68.176225 146.073345 \r\nL 69.70569 152.103766 \r\nL 71.235156 156.612573 \r\nL 72.764621 160.55271 \r\nL 74.294087 164.04398 \r\nL 77.353018 168.806506 \r\nL 78.882483 170.621659 \r\nL 80.411949 171.926794 \r\nL 81.941414 173.789194 \r\nL 83.47088 174.898142 \r\nL 85.000345 175.759787 \r\nL 88.059276 178.165474 \r\nL 89.588742 179.391002 \r\nL 91.118208 179.485252 \r\nL 92.647673 180.57918 \r\nL 94.177139 181.221991 \r\nL 95.706604 182.148038 \r\nL 97.23607 182.817539 \r\nL 98.765535 183.327089 \r\nL 100.295001 184.186543 \r\nL 101.824466 184.561251 \r\nL 103.353932 185.272405 \r\nL 104.883397 185.616949 \r\nL 106.412863 185.773304 \r\nL 107.942328 186.621863 \r\nL 109.471794 186.913515 \r\nL 111.001259 187.51724 \r\nL 112.530725 187.715462 \r\nL 114.06019 188.174171 \r\nL 115.589656 188.904329 \r\nL 117.119121 189.253172 \r\nL 118.648587 189.327613 \r\nL 120.178052 189.884177 \r\nL 121.707518 190.241922 \r\nL 123.236983 190.902383 \r\nL 126.295914 191.152045 \r\nL 127.82538 191.842623 \r\nL 129.354845 191.885544 \r\nL 132.413776 192.556177 \r\nL 133.943242 193.099973 \r\nL 135.472707 193.123091 \r\nL 137.002173 193.892212 \r\nL 138.531638 193.964592 \r\nL 140.061104 194.197288 \r\nL 141.590569 194.583769 \r\nL 143.120035 194.727752 \r\nL 144.6495 194.615609 \r\nL 146.178966 195.760679 \r\nL 147.708431 195.298822 \r\nL 149.237897 196.149992 \r\nL 152.296828 196.05164 \r\nL 153.826293 196.576695 \r\nL 155.355759 196.3268 \r\nL 156.885224 196.818212 \r\nL 158.41469 196.800403 \r\nL 159.944155 197.491924 \r\nL 161.473621 197.671364 \r\nL 163.003086 197.555861 \r\nL 164.532552 197.660334 \r\nL 167.591483 198.55819 \r\nL 169.120948 198.543895 \r\nL 170.650414 198.805621 \r\nL 172.17988 199.348608 \r\nL 173.709345 199.148137 \r\nL 175.238811 199.273587 \r\nL 176.768276 199.669104 \r\nL 178.297742 199.826121 \r\nL 179.827207 200.140703 \r\nL 181.356673 200.146313 \r\nL 184.415604 200.708628 \r\nL 185.945069 200.158847 \r\nL 187.474535 200.802178 \r\nL 190.533466 201.126973 \r\nL 192.062931 201.465772 \r\nL 196.651328 201.840375 \r\nL 199.710259 202.429331 \r\nL 201.239724 202.397575 \r\nL 202.76919 202.485169 \r\nL 204.298655 202.826832 \r\nL 205.828121 202.830419 \r\nL 208.887052 203.348576 \r\nL 210.416517 203.463619 \r\nL 213.475448 204.074328 \r\nL 215.004914 203.974745 \r\nL 216.534379 204.338961 \r\nL 218.063845 204.060853 \r\nL 219.59331 204.479233 \r\nL 221.122776 204.423285 \r\nL 222.652241 205.003769 \r\nL 224.181707 205.14209 \r\nL 225.711172 204.953974 \r\nL 227.240638 205.047984 \r\nL 228.770103 204.820871 \r\nL 230.299569 205.205956 \r\nL 231.829034 205.104865 \r\nL 233.3585 205.533048 \r\nL 234.887965 205.802502 \r\nL 236.417431 205.726973 \r\nL 237.946896 205.940593 \r\nL 239.476362 206.622343 \r\nL 241.005827 206.237592 \r\nL 242.535293 206.747331 \r\nL 244.064758 206.296717 \r\nL 245.594224 206.359662 \r\nL 247.123689 207.245913 \r\nL 248.653155 207.075757 \r\nL 250.18262 207.219705 \r\nL 251.712086 207.117079 \r\nL 253.241552 207.211655 \r\nL 254.771017 207.557514 \r\nL 257.829948 207.478913 \r\nL 259.359414 207.559327 \r\nL 260.888879 207.906264 \r\nL 262.418345 207.804039 \r\nL 263.94781 207.818028 \r\nL 265.477276 208.12548 \r\nL 267.006741 208.139141 \r\nL 268.536207 208.394831 \r\nL 270.065672 208.345008 \r\nL 271.595138 208.562691 \r\nL 273.124603 208.594429 \r\nL 274.654069 209.012553 \r\nL 276.183534 209.043353 \r\nL 277.713 208.927581 \r\nL 279.242465 208.954275 \r\nL 282.301396 209.362997 \r\nL 283.830862 209.45924 \r\nL 285.360327 209.818932 \r\nL 286.889793 209.620835 \r\nL 288.419258 209.906395 \r\nL 289.948724 209.999099 \r\nL 291.478189 209.732075 \r\nL 294.53712 210.417312 \r\nL 296.066586 210.256883 \r\nL 297.596051 210.35009 \r\nL 299.125517 210.799321 \r\nL 300.654982 210.607541 \r\nL 302.184448 210.932061 \r\nL 303.713913 210.358797 \r\nL 308.30231 211.275783 \r\nL 311.361241 211.306795 \r\nL 312.890706 211.702423 \r\nL 314.420172 211.305105 \r\nL 315.949637 212.023964 \r\nL 317.479103 211.908127 \r\nL 319.008568 212.101612 \r\nL 320.538034 211.756818 \r\nL 322.067499 212.307368 \r\nL 325.12643 212.487889 \r\nL 326.655896 212.259123 \r\nL 328.185361 212.835393 \r\nL 329.714827 212.428814 \r\nL 331.244292 212.681457 \r\nL 332.773758 212.310569 \r\nL 334.303224 213.021002 \r\nL 335.832689 212.811492 \r\nL 337.362155 212.95712 \r\nL 338.89162 212.696771 \r\nL 340.421086 213.392497 \r\nL 343.480017 213.458297 \r\nL 346.538948 213.993189 \r\nL 348.068413 213.551199 \r\nL 349.597879 214.060655 \r\nL 351.127344 213.646692 \r\nL 354.186275 214.061378 \r\nL 355.715741 214.29676 \r\nL 357.245206 213.965924 \r\nL 358.774672 214.340215 \r\nL 360.304137 213.920359 \r\nL 361.833603 214.228014 \r\nL 363.363068 214.756364 \r\nL 363.363068 214.756364 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_18\">\r\n    <path clip-path=\"url(#p5b623d9b55)\" d=\"M 58.999432 51.446031 \r\nL 60.528897 89.486782 \r\nL 62.058363 104.413223 \r\nL 65.117294 125.924768 \r\nL 66.646759 133.995402 \r\nL 68.176225 139.516935 \r\nL 69.70569 145.606678 \r\nL 71.235156 150.243823 \r\nL 72.764621 154.029186 \r\nL 74.294087 155.663592 \r\nL 75.823552 159.565912 \r\nL 77.353018 160.610709 \r\nL 78.882483 162.131761 \r\nL 80.411949 162.622139 \r\nL 81.941414 161.972481 \r\nL 83.47088 164.604904 \r\nL 85.000345 166.676725 \r\nL 86.529811 166.620002 \r\nL 89.588742 168.484828 \r\nL 91.118208 169.207372 \r\nL 92.647673 169.167876 \r\nL 94.177139 170.761695 \r\nL 95.706604 170.524867 \r\nL 97.23607 170.659065 \r\nL 98.765535 170.9691 \r\nL 100.295001 173.213943 \r\nL 101.824466 172.41828 \r\nL 103.353932 173.745396 \r\nL 104.883397 173.359863 \r\nL 106.412863 174.26291 \r\nL 107.942328 173.805197 \r\nL 109.471794 174.412014 \r\nL 111.001259 173.534606 \r\nL 112.530725 174.745515 \r\nL 114.06019 174.508746 \r\nL 115.589656 175.726568 \r\nL 117.119121 174.99634 \r\nL 118.648587 175.253347 \r\nL 120.178052 174.92833 \r\nL 121.707518 176.347318 \r\nL 123.236983 175.968853 \r\nL 124.766449 176.690548 \r\nL 126.295914 176.377493 \r\nL 127.82538 177.293285 \r\nL 129.354845 176.951375 \r\nL 130.884311 177.783388 \r\nL 132.413776 176.209814 \r\nL 133.943242 177.53006 \r\nL 135.472707 177.682813 \r\nL 138.531638 176.594906 \r\nL 140.061104 177.92197 \r\nL 141.590569 175.903998 \r\nL 143.120035 177.725953 \r\nL 146.178966 176.98653 \r\nL 147.708431 177.834141 \r\nL 149.237897 175.308011 \r\nL 150.767362 176.866251 \r\nL 152.296828 177.239203 \r\nL 153.826293 177.160413 \r\nL 155.355759 176.813135 \r\nL 156.885224 177.783049 \r\nL 158.41469 176.794346 \r\nL 159.944155 177.887196 \r\nL 161.473621 177.493214 \r\nL 163.003086 177.399934 \r\nL 164.532552 177.957456 \r\nL 166.062017 177.416433 \r\nL 169.120948 177.927494 \r\nL 170.650414 177.271391 \r\nL 173.709345 177.278004 \r\nL 175.238811 177.004809 \r\nL 176.768276 178.448305 \r\nL 178.297742 178.6507 \r\nL 179.827207 176.454329 \r\nL 181.356673 175.867537 \r\nL 182.886138 175.679997 \r\nL 184.415604 178.283443 \r\nL 185.945069 177.704438 \r\nL 187.474535 176.927313 \r\nL 189.004 177.827783 \r\nL 190.533466 177.834825 \r\nL 192.062931 177.688905 \r\nL 193.592397 176.780033 \r\nL 195.121862 177.54469 \r\nL 196.651328 176.802932 \r\nL 198.180793 177.288858 \r\nL 199.710259 176.39553 \r\nL 201.239724 177.103698 \r\nL 202.76919 176.854673 \r\nL 204.298655 178.132468 \r\nL 205.828121 176.04199 \r\nL 207.357586 177.351003 \r\nL 208.887052 175.370756 \r\nL 213.475448 177.47015 \r\nL 215.004914 177.382362 \r\nL 216.534379 176.557356 \r\nL 218.063845 176.025661 \r\nL 219.59331 176.77514 \r\nL 221.122776 177.735451 \r\nL 222.652241 177.045511 \r\nL 224.181707 173.178112 \r\nL 225.711172 175.271971 \r\nL 227.240638 176.143768 \r\nL 228.770103 175.08007 \r\nL 230.299569 176.058164 \r\nL 231.829034 176.179128 \r\nL 233.3585 177.176961 \r\nL 236.417431 175.686406 \r\nL 237.946896 175.449688 \r\nL 239.476362 174.227152 \r\nL 241.005827 175.443683 \r\nL 242.535293 176.418545 \r\nL 244.064758 175.987447 \r\nL 245.594224 176.256175 \r\nL 247.123689 175.281729 \r\nL 248.653155 175.947482 \r\nL 250.18262 174.208201 \r\nL 251.712086 175.334338 \r\nL 253.241552 174.884277 \r\nL 254.771017 175.347781 \r\nL 256.300483 175.18786 \r\nL 259.359414 176.472732 \r\nL 260.888879 174.944769 \r\nL 262.418345 175.329971 \r\nL 263.94781 174.678609 \r\nL 265.477276 175.224484 \r\nL 267.006741 174.184104 \r\nL 268.536207 174.044685 \r\nL 270.065672 175.04699 \r\nL 271.595138 174.858341 \r\nL 273.124603 174.944413 \r\nL 274.654069 174.305432 \r\nL 276.183534 175.056842 \r\nL 277.713 174.065345 \r\nL 279.242465 174.174698 \r\nL 280.771931 174.156491 \r\nL 282.301396 173.033259 \r\nL 283.830862 175.068152 \r\nL 285.360327 173.508337 \r\nL 286.889793 172.632939 \r\nL 288.419258 172.80712 \r\nL 289.948724 174.234455 \r\nL 291.478189 173.023918 \r\nL 293.007655 172.289163 \r\nL 294.53712 174.094057 \r\nL 296.066586 172.642231 \r\nL 299.125517 172.683365 \r\nL 300.654982 173.647567 \r\nL 302.184448 172.718707 \r\nL 303.713913 172.916216 \r\nL 305.243379 170.57068 \r\nL 306.772844 174.208062 \r\nL 308.30231 172.903337 \r\nL 309.831775 170.458228 \r\nL 311.361241 173.264605 \r\nL 312.890706 173.939155 \r\nL 314.420172 173.471884 \r\nL 315.949637 170.05022 \r\nL 317.479103 173.426978 \r\nL 319.008568 171.24122 \r\nL 320.538034 173.609376 \r\nL 322.067499 173.83082 \r\nL 323.596965 173.534789 \r\nL 325.12643 171.470769 \r\nL 326.655896 171.5049 \r\nL 328.185361 169.398118 \r\nL 329.714827 173.118512 \r\nL 331.244292 172.717188 \r\nL 332.773758 171.4018 \r\nL 334.303224 173.414062 \r\nL 335.832689 171.002177 \r\nL 337.362155 172.127778 \r\nL 338.89162 173.016044 \r\nL 340.421086 171.207316 \r\nL 341.950551 170.958761 \r\nL 343.480017 169.840502 \r\nL 345.009482 172.215526 \r\nL 346.538948 171.663247 \r\nL 348.068413 168.847939 \r\nL 349.597879 170.93631 \r\nL 351.127344 170.281589 \r\nL 352.65681 171.721571 \r\nL 354.186275 170.117025 \r\nL 355.715741 170.8585 \r\nL 357.245206 169.973277 \r\nL 358.774672 171.444003 \r\nL 360.304137 170.959255 \r\nL 361.833603 169.564494 \r\nL 363.363068 170.040831 \r\nL 363.363068 170.040831 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 43.78125 224.64 \r\nL 43.78125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 378.58125 224.64 \r\nL 378.58125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 43.78125 224.64 \r\nL 378.58125 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 43.78125 7.2 \r\nL 378.58125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 277.635938 44.55625 \r\nL 371.58125 44.55625 \r\nQ 373.58125 44.55625 373.58125 42.55625 \r\nL 373.58125 14.2 \r\nQ 373.58125 12.2 371.58125 12.2 \r\nL 277.635938 12.2 \r\nQ 275.635938 12.2 275.635938 14.2 \r\nL 275.635938 42.55625 \r\nQ 275.635938 44.55625 277.635938 44.55625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\">\r\n     <path d=\"M 279.635938 20.298437 \r\nL 299.635938 20.298437 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_20\"/>\r\n    <g id=\"text_19\">\r\n     <!-- Training loss -->\r\n     <defs>\r\n      <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n     </defs>\r\n     <g transform=\"translate(307.635938 23.798437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"239.888672\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"267.671875\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"331.050781\" xlink:href=\"#DejaVuSans-103\"/>\r\n      <use x=\"394.527344\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"426.314453\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"454.097656\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"515.279297\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"567.378906\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_21\">\r\n     <path d=\"M 279.635938 34.976562 \r\nL 299.635938 34.976562 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_22\"/>\r\n    <g id=\"text_20\">\r\n     <!-- Test loss -->\r\n     <defs>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n     </defs>\r\n     <g transform=\"translate(307.635938 38.476562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"44.083984\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"105.607422\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"157.707031\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"196.916016\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"228.703125\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"256.486328\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"317.667969\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"369.767578\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p5b623d9b55\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(keras_history.history['loss'], label='Training loss')\n",
    "plt.plot(keras_history.history['val_loss'], color='red', label='Test loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkvqbRxUjewo"
   },
   "source": [
    "#**IMPROVING YOUR NEURAL NETWORK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h96i8MOKjlPb"
   },
   "source": [
    "Great! Now you know how to build a basic artificial neural network in Keras. However, ANN's are extremely prone to overfitting, so always keep a close tab on that. We will now see how various methods are deployed in keras to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KF4Hu4CVj9AK"
   },
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0M6IXEmkBUt"
   },
   "source": [
    "You can apply an L1, L2 or both L1 and L2 regularizers to a layer using tf.keras.regularizers. The value of $\\lambda$ is specified as an argument of the class. For example\n",
    "\n",
    "\n",
    "```\n",
    "model.add(tf.keras.layers.Dense(units=30, activation='relu', activity_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c1egJo7ylNrQ"
   },
   "source": [
    "Click [here](https://keras.io/api/layers/regularizers/#l1-class) to check out the documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UXYeM_PlYvj"
   },
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwZfBan3lkgw"
   },
   "source": [
    "Nothing complicated here. Just do this:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Jdr1DsTlw86"
   },
   "source": [
    "[Link for BatchNorm](https://keras.io/api/layers/normalization_layers/batch_normalization/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qa6aX97wmB2f"
   },
   "source": [
    "##Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jA6A5QBRmEsi"
   },
   "source": [
    "Nothing complicated here too. The probability of a neuron being \"dropped out\" is specified. Higher the value, the \"simpler\" the neural network is. But make sure not to specify too high a dropout rate else the model will undefit\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBalrMLBnXep"
   },
   "source": [
    "#**PUTTING IT ALL TOGETHER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXTTGh_5nZ_M"
   },
   "source": [
    "Here is all of the concepts we have just learnt. Please note that all the abovementioned techniques to prevent overfitting have been implemented below, to get an idea of how they are used in Keras. In reality, all these are not necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "dQDQMwlBjd9N",
    "outputId": "ad70f7c3-9e8d-4080-d127-b5ec83f1fed0",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 30)                330       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 30)                120       \n_________________________________________________________________\ndropout (Dropout)            (None, 30)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 15)                465       \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 15)                60        \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 15)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 5)                 80        \n=================================================================\nTotal params: 1,055\nTrainable params: 965\nNon-trainable params: 90\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=10,))\n",
    "model.add(tf.keras.layers.Dense(units=30, activation='relu', activity_regularizer=tf.keras.regularizers.l2(0.01))) \n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.125))\n",
    "model.add(tf.keras.layers.Dense(units=15, activation='relu', activity_regularizer=tf.keras.regularizers.l2(0.01))) \n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(units=5, activation='softmax')) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6b86CyX5qWB4",
    "outputId": "69944b9e-5f5f-4210-c3b0-cc229b6472d9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===] - 1s 162us/sample - loss: 0.6764 - accuracy: 0.7640 - val_loss: 0.4778 - val_accuracy: 0.8420\n",
      "Epoch 69/200\n",
      "3500/3500 [==============================] - 1s 158us/sample - loss: 0.6650 - accuracy: 0.7600 - val_loss: 0.4956 - val_accuracy: 0.8293\n",
      "Epoch 70/200\n",
      "3500/3500 [==============================] - 1s 172us/sample - loss: 0.6740 - accuracy: 0.7651 - val_loss: 0.4824 - val_accuracy: 0.8393\n",
      "Epoch 71/200\n",
      "3500/3500 [==============================] - 1s 159us/sample - loss: 0.6722 - accuracy: 0.7629 - val_loss: 0.4792 - val_accuracy: 0.8407\n",
      "Epoch 72/200\n",
      "3500/3500 [==============================] - 1s 158us/sample - loss: 0.6657 - accuracy: 0.7609 - val_loss: 0.4779 - val_accuracy: 0.8387\n",
      "Epoch 73/200\n",
      "3500/3500 [==============================] - 1s 158us/sample - loss: 0.6661 - accuracy: 0.7651 - val_loss: 0.4845 - val_accuracy: 0.8347\n",
      "Epoch 74/200\n",
      "3500/3500 [==============================] - 1s 161us/sample - loss: 0.6687 - accuracy: 0.7723 - val_loss: 0.4769 - val_accuracy: 0.8433\n",
      "Epoch 75/200\n",
      "3500/3500 [==============================] - 1s 158us/sample - loss: 0.6730 - accuracy: 0.7577 - val_loss: 0.4771 - val_accuracy: 0.8400\n",
      "Epoch 76/200\n",
      "3500/3500 [==============================] - 1s 159us/sample - loss: 0.6799 - accuracy: 0.7566 - val_loss: 0.4771 - val_accuracy: 0.8387\n",
      "Epoch 77/200\n",
      "3500/3500 [==============================] - 1s 159us/sample - loss: 0.6484 - accuracy: 0.7711 - val_loss: 0.4866 - val_accuracy: 0.8287\n",
      "Epoch 78/200\n",
      "3500/3500 [==============================] - 1s 159us/sample - loss: 0.6703 - accuracy: 0.7674 - val_loss: 0.4864 - val_accuracy: 0.8327\n",
      "Epoch 79/200\n",
      "3500/3500 [==============================] - 1s 158us/sample - loss: 0.6522 - accuracy: 0.7749 - val_loss: 0.4790 - val_accuracy: 0.8380\n",
      "Epoch 80/200\n",
      "3500/3500 [==============================] - 1s 163us/sample - loss: 0.6782 - accuracy: 0.7549 - val_loss: 0.4915 - val_accuracy: 0.8353\n",
      "Epoch 81/200\n",
      "3500/3500 [==============================] - 1s 157us/sample - loss: 0.6545 - accuracy: 0.7737 - val_loss: 0.4779 - val_accuracy: 0.8367\n",
      "Epoch 82/200\n",
      "3500/3500 [==============================] - 1s 160us/sample - loss: 0.6662 - accuracy: 0.7649 - val_loss: 0.4695 - val_accuracy: 0.8413\n",
      "Epoch 83/200\n",
      "3500/3500 [==============================] - 1s 159us/sample - loss: 0.6510 - accuracy: 0.7723 - val_loss: 0.4766 - val_accuracy: 0.8347\n",
      "Epoch 84/200\n",
      "3500/3500 [==============================] - 1s 173us/sample - loss: 0.6417 - accuracy: 0.7771 - val_loss: 0.4668 - val_accuracy: 0.8440\n",
      "Epoch 85/200\n",
      "3500/3500 [==============================] - 1s 174us/sample - loss: 0.6727 - accuracy: 0.7600 - val_loss: 0.4740 - val_accuracy: 0.8400\n",
      "Epoch 86/200\n",
      "3500/3500 [==============================] - 1s 160us/sample - loss: 0.6485 - accuracy: 0.7726 - val_loss: 0.4819 - val_accuracy: 0.8313\n",
      "Epoch 87/200\n",
      "3500/3500 [==============================] - 1s 160us/sample - loss: 0.6647 - accuracy: 0.7571 - val_loss: 0.4828 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "3500/3500 [==============================] - 1s 160us/sample - loss: 0.6550 - accuracy: 0.7723 - val_loss: 0.4771 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "3500/3500 [==============================] - 1s 161us/sample - loss: 0.6372 - accuracy: 0.7657 - val_loss: 0.4788 - val_accuracy: 0.8480\n",
      "Epoch 90/200\n",
      "3500/3500 [==============================] - 1s 196us/sample - loss: 0.6470 - accuracy: 0.7700 - val_loss: 0.4638 - val_accuracy: 0.8433\n",
      "Epoch 91/200\n",
      "3500/3500 [==============================] - 1s 157us/sample - loss: 0.6640 - accuracy: 0.7689 - val_loss: 0.4721 - val_accuracy: 0.8393\n",
      "Epoch 92/200\n",
      "3500/3500 [==============================] - 1s 164us/sample - loss: 0.6643 - accuracy: 0.7660 - val_loss: 0.4751 - val_accuracy: 0.8353\n",
      "Epoch 93/200\n",
      "3500/3500 [==============================] - 1s 176us/sample - loss: 0.6481 - accuracy: 0.7706 - val_loss: 0.4863 - val_accuracy: 0.8280\n",
      "Epoch 94/200\n",
      "3500/3500 [==============================] - 1s 186us/sample - loss: 0.6560 - accuracy: 0.7646 - val_loss: 0.4815 - val_accuracy: 0.8340\n",
      "Epoch 95/200\n",
      "3500/3500 [==============================] - 1s 159us/sample - loss: 0.6309 - accuracy: 0.7809 - val_loss: 0.4710 - val_accuracy: 0.8440\n",
      "Epoch 96/200\n",
      "3500/3500 [==============================] - 1s 176us/sample - loss: 0.6774 - accuracy: 0.7591 - val_loss: 0.4974 - val_accuracy: 0.8273\n",
      "Epoch 97/200\n",
      "3500/3500 [==============================] - 1s 177us/sample - loss: 0.6523 - accuracy: 0.7677 - val_loss: 0.4825 - val_accuracy: 0.8367\n",
      "Epoch 98/200\n",
      "3500/3500 [==============================] - 1s 158us/sample - loss: 0.6303 - accuracy: 0.7766 - val_loss: 0.4703 - val_accuracy: 0.8373\n",
      "Epoch 99/200\n",
      "3500/3500 [==============================] - 1s 214us/sample - loss: 0.6710 - accuracy: 0.7663 - val_loss: 0.4899 - val_accuracy: 0.8393\n",
      "Epoch 100/200\n",
      "3500/3500 [==============================] - 1s 208us/sample - loss: 0.6444 - accuracy: 0.7700 - val_loss: 0.4818 - val_accuracy: 0.8367\n",
      "Epoch 101/200\n",
      "3500/3500 [==============================] - 1s 186us/sample - loss: 0.6462 - accuracy: 0.7677 - val_loss: 0.4842 - val_accuracy: 0.8407\n",
      "Epoch 102/200\n",
      "3500/3500 [==============================] - 1s 177us/sample - loss: 0.6447 - accuracy: 0.7689 - val_loss: 0.4720 - val_accuracy: 0.8367\n",
      "Epoch 103/200\n",
      "3500/3500 [==============================] - 1s 159us/sample - loss: 0.6227 - accuracy: 0.7786 - val_loss: 0.4778 - val_accuracy: 0.8307\n",
      "Epoch 104/200\n",
      "3500/3500 [==============================] - 1s 162us/sample - loss: 0.6354 - accuracy: 0.7729 - val_loss: 0.4702 - val_accuracy: 0.8347\n",
      "Epoch 105/200\n",
      "3500/3500 [==============================] - 1s 186us/sample - loss: 0.6459 - accuracy: 0.7717 - val_loss: 0.4721 - val_accuracy: 0.8360\n",
      "Epoch 106/200\n",
      "3500/3500 [==============================] - 1s 185us/sample - loss: 0.6566 - accuracy: 0.7643 - val_loss: 0.4712 - val_accuracy: 0.8367\n",
      "Epoch 107/200\n",
      "3500/3500 [==============================] - 1s 160us/sample - loss: 0.6399 - accuracy: 0.7749 - val_loss: 0.4711 - val_accuracy: 0.8433\n",
      "Epoch 108/200\n",
      "3500/3500 [==============================] - 1s 160us/sample - loss: 0.6613 - accuracy: 0.7706 - val_loss: 0.4788 - val_accuracy: 0.8340\n",
      "Epoch 109/200\n",
      "3500/3500 [==============================] - 1s 201us/sample - loss: 0.6463 - accuracy: 0.7671 - val_loss: 0.4778 - val_accuracy: 0.8327\n",
      "Epoch 110/200\n",
      "3500/3500 [==============================] - 1s 203us/sample - loss: 0.6686 - accuracy: 0.7594 - val_loss: 0.4937 - val_accuracy: 0.8307\n",
      "Epoch 111/200\n",
      "3500/3500 [==============================] - 1s 186us/sample - loss: 0.6263 - accuracy: 0.7780 - val_loss: 0.4624 - val_accuracy: 0.8527\n",
      "Epoch 112/200\n",
      "3500/3500 [==============================] - 1s 174us/sample - loss: 0.6463 - accuracy: 0.7703 - val_loss: 0.4709 - val_accuracy: 0.8413\n",
      "Epoch 113/200\n",
      "3500/3500 [==============================] - 1s 170us/sample - loss: 0.6493 - accuracy: 0.7737 - val_loss: 0.4795 - val_accuracy: 0.8313\n",
      "Epoch 114/200\n",
      "3500/3500 [==============================] - 1s 238us/sample - loss: 0.6502 - accuracy: 0.7697 - val_loss: 0.4857 - val_accuracy: 0.8293\n",
      "Epoch 115/200\n",
      "3500/3500 [==============================] - 1s 179us/sample - loss: 0.6372 - accuracy: 0.7754 - val_loss: 0.4753 - val_accuracy: 0.8407\n",
      "Epoch 116/200\n",
      "3500/3500 [==============================] - 1s 168us/sample - loss: 0.6485 - accuracy: 0.7743 - val_loss: 0.4856 - val_accuracy: 0.8307\n",
      "Epoch 117/200\n",
      "3500/3500 [==============================] - 1s 190us/sample - loss: 0.6587 - accuracy: 0.7660 - val_loss: 0.4764 - val_accuracy: 0.8373\n",
      "Epoch 118/200\n",
      "3500/3500 [==============================] - 1s 173us/sample - loss: 0.6496 - accuracy: 0.7731 - val_loss: 0.4783 - val_accuracy: 0.8380\n",
      "Epoch 119/200\n",
      "3500/3500 [==============================] - 1s 175us/sample - loss: 0.6425 - accuracy: 0.7657 - val_loss: 0.4652 - val_accuracy: 0.8433\n",
      "Epoch 120/200\n",
      "3500/3500 [==============================] - 1s 159us/sample - loss: 0.6519 - accuracy: 0.7660 - val_loss: 0.4849 - val_accuracy: 0.8307\n",
      "Epoch 121/200\n",
      "3500/3500 [==============================] - 1s 161us/sample - loss: 0.6381 - accuracy: 0.7806 - val_loss: 0.4796 - val_accuracy: 0.8413\n",
      "Epoch 122/200\n",
      "3500/3500 [==============================] - 1s 186us/sample - loss: 0.6683 - accuracy: 0.7654 - val_loss: 0.4814 - val_accuracy: 0.8360\n",
      "Epoch 123/200\n",
      "3500/3500 [==============================] - 1s 187us/sample - loss: 0.6371 - accuracy: 0.7746 - val_loss: 0.4701 - val_accuracy: 0.8393\n",
      "Epoch 124/200\n",
      "3500/3500 [==============================] - 1s 166us/sample - loss: 0.6535 - accuracy: 0.7657 - val_loss: 0.4737 - val_accuracy: 0.8367\n",
      "Epoch 125/200\n",
      "3500/3500 [==============================] - 1s 160us/sample - loss: 0.6668 - accuracy: 0.7634 - val_loss: 0.4677 - val_accuracy: 0.8420\n",
      "Epoch 126/200\n",
      "3500/3500 [==============================] - 1s 174us/sample - loss: 0.6384 - accuracy: 0.7769 - val_loss: 0.4988 - val_accuracy: 0.8187\n",
      "Epoch 127/200\n",
      "3500/3500 [==============================] - 1s 159us/sample - loss: 0.6486 - accuracy: 0.7749 - val_loss: 0.4683 - val_accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "3500/3500 [==============================] - 1s 175us/sample - loss: 0.6241 - accuracy: 0.7766 - val_loss: 0.4764 - val_accuracy: 0.8320\n",
      "Epoch 129/200\n",
      "3500/3500 [==============================] - 1s 164us/sample - loss: 0.6168 - accuracy: 0.7757 - val_loss: 0.4754 - val_accuracy: 0.8340\n",
      "Epoch 130/200\n",
      "3500/3500 [==============================] - 1s 169us/sample - loss: 0.6119 - accuracy: 0.7829 - val_loss: 0.4678 - val_accuracy: 0.8367\n",
      "Epoch 131/200\n",
      "3500/3500 [==============================] - 1s 164us/sample - loss: 0.6494 - accuracy: 0.7671 - val_loss: 0.4971 - val_accuracy: 0.8233\n",
      "Epoch 132/200\n",
      "3500/3500 [==============================] - 1s 178us/sample - loss: 0.6172 - accuracy: 0.7869 - val_loss: 0.4814 - val_accuracy: 0.8313\n",
      "Epoch 133/200\n",
      "3500/3500 [==============================] - 1s 165us/sample - loss: 0.6402 - accuracy: 0.7754 - val_loss: 0.4760 - val_accuracy: 0.8293\n",
      "Epoch 134/200\n",
      "3500/3500 [==============================] - 1s 161us/sample - loss: 0.6327 - accuracy: 0.7746 - val_loss: 0.4703 - val_accuracy: 0.8307\n",
      "Epoch 135/200\n",
      "3500/3500 [==============================] - 1s 166us/sample - loss: 0.6409 - accuracy: 0.7694 - val_loss: 0.4745 - val_accuracy: 0.8373\n",
      "Epoch 136/200\n",
      "3500/3500 [==============================] - 1s 175us/sample - loss: 0.6651 - accuracy: 0.7637 - val_loss: 0.4654 - val_accuracy: 0.8373\n",
      "Epoch 137/200\n",
      "3500/3500 [==============================] - 1s 179us/sample - loss: 0.6383 - accuracy: 0.7711 - val_loss: 0.4795 - val_accuracy: 0.8347\n",
      "Epoch 138/200\n",
      "3500/3500 [==============================] - 1s 188us/sample - loss: 0.6289 - accuracy: 0.7849 - val_loss: 0.4852 - val_accuracy: 0.8280\n",
      "Epoch 139/200\n",
      "3500/3500 [==============================] - 1s 186us/sample - loss: 0.6344 - accuracy: 0.7786 - val_loss: 0.4715 - val_accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "3500/3500 [==============================] - 1s 227us/sample - loss: 0.6284 - accuracy: 0.7814 - val_loss: 0.4617 - val_accuracy: 0.8373\n",
      "Epoch 141/200\n",
      "3500/3500 [==============================] - 1s 239us/sample - loss: 0.6227 - accuracy: 0.7786 - val_loss: 0.4759 - val_accuracy: 0.8267\n",
      "Epoch 142/200\n",
      "3500/3500 [==============================] - 1s 250us/sample - loss: 0.6376 - accuracy: 0.7669 - val_loss: 0.4572 - val_accuracy: 0.8380\n",
      "Epoch 143/200\n",
      "3500/3500 [==============================] - 1s 246us/sample - loss: 0.6346 - accuracy: 0.7749 - val_loss: 0.4727 - val_accuracy: 0.8340\n",
      "Epoch 144/200\n",
      "3500/3500 [==============================] - 1s 193us/sample - loss: 0.6354 - accuracy: 0.7686 - val_loss: 0.4836 - val_accuracy: 0.8240\n",
      "Epoch 145/200\n",
      "3500/3500 [==============================] - 1s 182us/sample - loss: 0.6326 - accuracy: 0.7829 - val_loss: 0.4620 - val_accuracy: 0.8407\n",
      "Epoch 146/200\n",
      "3500/3500 [==============================] - 1s 215us/sample - loss: 0.6596 - accuracy: 0.7663 - val_loss: 0.4831 - val_accuracy: 0.8173\n",
      "Epoch 147/200\n",
      "3500/3500 [==============================] - 1s 196us/sample - loss: 0.6428 - accuracy: 0.7686 - val_loss: 0.4666 - val_accuracy: 0.8300\n",
      "Epoch 148/200\n",
      "3500/3500 [==============================] - 1s 205us/sample - loss: 0.6181 - accuracy: 0.7823 - val_loss: 0.4699 - val_accuracy: 0.8280\n",
      "Epoch 149/200\n",
      "3500/3500 [==============================] - 1s 193us/sample - loss: 0.6298 - accuracy: 0.7814 - val_loss: 0.4737 - val_accuracy: 0.8313\n",
      "Epoch 150/200\n",
      "3500/3500 [==============================] - 1s 230us/sample - loss: 0.6313 - accuracy: 0.7749 - val_loss: 0.4746 - val_accuracy: 0.8280\n",
      "Epoch 151/200\n",
      "3500/3500 [==============================] - 1s 196us/sample - loss: 0.6329 - accuracy: 0.7774 - val_loss: 0.4598 - val_accuracy: 0.8367\n",
      "Epoch 152/200\n",
      "3500/3500 [==============================] - 1s 254us/sample - loss: 0.6303 - accuracy: 0.7737 - val_loss: 0.4726 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "3500/3500 [==============================] - 1s 247us/sample - loss: 0.6403 - accuracy: 0.7706 - val_loss: 0.4611 - val_accuracy: 0.8347\n",
      "Epoch 154/200\n",
      "3500/3500 [==============================] - 1s 262us/sample - loss: 0.6257 - accuracy: 0.7797 - val_loss: 0.4577 - val_accuracy: 0.8373\n",
      "Epoch 155/200\n",
      "3500/3500 [==============================] - 1s 246us/sample - loss: 0.6373 - accuracy: 0.7669 - val_loss: 0.4612 - val_accuracy: 0.8387\n",
      "Epoch 156/200\n",
      "3500/3500 [==============================] - 1s 187us/sample - loss: 0.6355 - accuracy: 0.7749 - val_loss: 0.4688 - val_accuracy: 0.8367\n",
      "Epoch 157/200\n",
      "3500/3500 [==============================] - 1s 210us/sample - loss: 0.6367 - accuracy: 0.7766 - val_loss: 0.4765 - val_accuracy: 0.8327\n",
      "Epoch 158/200\n",
      "3500/3500 [==============================] - 1s 210us/sample - loss: 0.6418 - accuracy: 0.7700 - val_loss: 0.4709 - val_accuracy: 0.8313\n",
      "Epoch 159/200\n",
      "3500/3500 [==============================] - 1s 180us/sample - loss: 0.6151 - accuracy: 0.7829 - val_loss: 0.4732 - val_accuracy: 0.8353\n",
      "Epoch 160/200\n",
      "3500/3500 [==============================] - 1s 198us/sample - loss: 0.6425 - accuracy: 0.7817 - val_loss: 0.4760 - val_accuracy: 0.8280\n",
      "Epoch 161/200\n",
      "3500/3500 [==============================] - 1s 170us/sample - loss: 0.6421 - accuracy: 0.7686 - val_loss: 0.4910 - val_accuracy: 0.8253\n",
      "Epoch 162/200\n",
      "3500/3500 [==============================] - 1s 240us/sample - loss: 0.6441 - accuracy: 0.7657 - val_loss: 0.4922 - val_accuracy: 0.8200\n",
      "Epoch 163/200\n",
      "3500/3500 [==============================] - 1s 214us/sample - loss: 0.6445 - accuracy: 0.7717 - val_loss: 0.4693 - val_accuracy: 0.8313\n",
      "Epoch 164/200\n",
      "3500/3500 [==============================] - 1s 217us/sample - loss: 0.6320 - accuracy: 0.7726 - val_loss: 0.4630 - val_accuracy: 0.8413\n",
      "Epoch 165/200\n",
      "3500/3500 [==============================] - 1s 202us/sample - loss: 0.6176 - accuracy: 0.7809 - val_loss: 0.4637 - val_accuracy: 0.8393\n",
      "Epoch 166/200\n",
      "3500/3500 [==============================] - 1s 198us/sample - loss: 0.6323 - accuracy: 0.7823 - val_loss: 0.4755 - val_accuracy: 0.8300\n",
      "Epoch 167/200\n",
      "3500/3500 [==============================] - 1s 200us/sample - loss: 0.6263 - accuracy: 0.7786 - val_loss: 0.4666 - val_accuracy: 0.8393\n",
      "Epoch 168/200\n",
      "3500/3500 [==============================] - 1s 177us/sample - loss: 0.6545 - accuracy: 0.7674 - val_loss: 0.4540 - val_accuracy: 0.8440\n",
      "Epoch 169/200\n",
      "3500/3500 [==============================] - 1s 165us/sample - loss: 0.6488 - accuracy: 0.7754 - val_loss: 0.4594 - val_accuracy: 0.8387\n",
      "Epoch 170/200\n",
      "3500/3500 [==============================] - 1s 195us/sample - loss: 0.6269 - accuracy: 0.7826 - val_loss: 0.4648 - val_accuracy: 0.8240\n",
      "Epoch 171/200\n",
      "3500/3500 [==============================] - 1s 224us/sample - loss: 0.6395 - accuracy: 0.7680 - val_loss: 0.4726 - val_accuracy: 0.8267\n",
      "Epoch 172/200\n",
      "3500/3500 [==============================] - 1s 250us/sample - loss: 0.6340 - accuracy: 0.7754 - val_loss: 0.4629 - val_accuracy: 0.8373\n",
      "Epoch 173/200\n",
      "3500/3500 [==============================] - 1s 180us/sample - loss: 0.6253 - accuracy: 0.7700 - val_loss: 0.4782 - val_accuracy: 0.8300\n",
      "Epoch 174/200\n",
      "3500/3500 [==============================] - 1s 163us/sample - loss: 0.6311 - accuracy: 0.7817 - val_loss: 0.4665 - val_accuracy: 0.8320\n",
      "Epoch 175/200\n",
      "3500/3500 [==============================] - 1s 165us/sample - loss: 0.6454 - accuracy: 0.7660 - val_loss: 0.4540 - val_accuracy: 0.8427\n",
      "Epoch 176/200\n",
      "3500/3500 [==============================] - 1s 194us/sample - loss: 0.6367 - accuracy: 0.7757 - val_loss: 0.4578 - val_accuracy: 0.8360\n",
      "Epoch 177/200\n",
      "3500/3500 [==============================] - 1s 230us/sample - loss: 0.6542 - accuracy: 0.7666 - val_loss: 0.4597 - val_accuracy: 0.8387\n",
      "Epoch 178/200\n",
      "3500/3500 [==============================] - 1s 178us/sample - loss: 0.6319 - accuracy: 0.7797 - val_loss: 0.4597 - val_accuracy: 0.8307\n",
      "Epoch 179/200\n",
      "3500/3500 [==============================] - 1s 168us/sample - loss: 0.6250 - accuracy: 0.7746 - val_loss: 0.4650 - val_accuracy: 0.8373\n",
      "Epoch 180/200\n",
      "3500/3500 [==============================] - 1s 219us/sample - loss: 0.6328 - accuracy: 0.7703 - val_loss: 0.4768 - val_accuracy: 0.8353\n",
      "Epoch 181/200\n",
      "3500/3500 [==============================] - 1s 209us/sample - loss: 0.6340 - accuracy: 0.7823 - val_loss: 0.4625 - val_accuracy: 0.8380\n",
      "Epoch 182/200\n",
      "3500/3500 [==============================] - 1s 171us/sample - loss: 0.6267 - accuracy: 0.7860 - val_loss: 0.4654 - val_accuracy: 0.8380\n",
      "Epoch 183/200\n",
      "3500/3500 [==============================] - 1s 174us/sample - loss: 0.6280 - accuracy: 0.7831 - val_loss: 0.4731 - val_accuracy: 0.8253\n",
      "Epoch 184/200\n",
      "3500/3500 [==============================] - 1s 166us/sample - loss: 0.6507 - accuracy: 0.7663 - val_loss: 0.4717 - val_accuracy: 0.8327\n",
      "Epoch 185/200\n",
      "3500/3500 [==============================] - 1s 174us/sample - loss: 0.6617 - accuracy: 0.7617 - val_loss: 0.4732 - val_accuracy: 0.8327\n",
      "Epoch 186/200\n",
      "3500/3500 [==============================] - 1s 173us/sample - loss: 0.6337 - accuracy: 0.7783 - val_loss: 0.4764 - val_accuracy: 0.8293\n",
      "Epoch 187/200\n",
      "3500/3500 [==============================] - 1s 180us/sample - loss: 0.5986 - accuracy: 0.7883 - val_loss: 0.4615 - val_accuracy: 0.8380\n",
      "Epoch 188/200\n",
      "3500/3500 [==============================] - 1s 164us/sample - loss: 0.6263 - accuracy: 0.7757 - val_loss: 0.4667 - val_accuracy: 0.8333\n",
      "Epoch 189/200\n",
      "3500/3500 [==============================] - 1s 179us/sample - loss: 0.6432 - accuracy: 0.7694 - val_loss: 0.4667 - val_accuracy: 0.8327\n",
      "Epoch 190/200\n",
      "3500/3500 [==============================] - 1s 164us/sample - loss: 0.6172 - accuracy: 0.7726 - val_loss: 0.4681 - val_accuracy: 0.8320\n",
      "Epoch 191/200\n",
      "3500/3500 [==============================] - 1s 164us/sample - loss: 0.6526 - accuracy: 0.7689 - val_loss: 0.4788 - val_accuracy: 0.8280\n",
      "Epoch 192/200\n",
      "3500/3500 [==============================] - 1s 164us/sample - loss: 0.6309 - accuracy: 0.7757 - val_loss: 0.4797 - val_accuracy: 0.8273\n",
      "Epoch 193/200\n",
      "3500/3500 [==============================] - 1s 182us/sample - loss: 0.6255 - accuracy: 0.7754 - val_loss: 0.4709 - val_accuracy: 0.8360\n",
      "Epoch 194/200\n",
      "3500/3500 [==============================] - 1s 172us/sample - loss: 0.6444 - accuracy: 0.7717 - val_loss: 0.4702 - val_accuracy: 0.8313\n",
      "Epoch 195/200\n",
      "3500/3500 [==============================] - 1s 192us/sample - loss: 0.6348 - accuracy: 0.7714 - val_loss: 0.4677 - val_accuracy: 0.8400\n",
      "Epoch 196/200\n",
      "3500/3500 [==============================] - 1s 185us/sample - loss: 0.6348 - accuracy: 0.7763 - val_loss: 0.4655 - val_accuracy: 0.8327\n",
      "Epoch 197/200\n",
      "3500/3500 [==============================] - 1s 176us/sample - loss: 0.6493 - accuracy: 0.7620 - val_loss: 0.4761 - val_accuracy: 0.8347\n",
      "Epoch 198/200\n",
      "3500/3500 [==============================] - 1s 170us/sample - loss: 0.6089 - accuracy: 0.7863 - val_loss: 0.4787 - val_accuracy: 0.8280\n",
      "Epoch 199/200\n",
      "3500/3500 [==============================] - 1s 178us/sample - loss: 0.6237 - accuracy: 0.7786 - val_loss: 0.4620 - val_accuracy: 0.8287\n",
      "Epoch 200/200\n",
      "3500/3500 [==============================] - 1s 158us/sample - loss: 0.6384 - accuracy: 0.7740 - val_loss: 0.4785 - val_accuracy: 0.8187\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "keras_history = model.fit(X_train, y_train , batch_size=16, epochs=200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "1BpghfAMqcEW",
    "outputId": "fc570e9a-d05f-447c-a698-3c80d651104d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a983101208>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n",
       "<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">\r\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\r\n",
       "  </style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 248.518125 \r\n",
       "L 372.103125 248.518125 \r\n",
       "L 372.103125 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 30.103125 224.64 \r\n",
       "L 364.903125 224.64 \r\n",
       "L 364.903125 7.2 \r\n",
       "L 30.103125 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"m5d29e222eb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m5d29e222eb\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 31.78125 66.40625 \r\n",
       "Q 24.171875 66.40625 20.328125 58.90625 \r\n",
       "Q 16.5 51.421875 16.5 36.375 \r\n",
       "Q 16.5 21.390625 20.328125 13.890625 \r\n",
       "Q 24.171875 6.390625 31.78125 6.390625 \r\n",
       "Q 39.453125 6.390625 43.28125 13.890625 \r\n",
       "Q 47.125 21.390625 47.125 36.375 \r\n",
       "Q 47.125 51.421875 43.28125 58.90625 \r\n",
       "Q 39.453125 66.40625 31.78125 66.40625 \r\n",
       "z\r\n",
       "M 31.78125 74.21875 \r\n",
       "Q 44.046875 74.21875 50.515625 64.515625 \r\n",
       "Q 56.984375 54.828125 56.984375 36.375 \r\n",
       "Q 56.984375 17.96875 50.515625 8.265625 \r\n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \r\n",
       "Q 6.59375 17.96875 6.59375 36.375 \r\n",
       "Q 6.59375 54.828125 13.0625 64.515625 \r\n",
       "Q 19.53125 74.21875 31.78125 74.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-48\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(42.140057 239.238438)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"83.557945\" xlink:href=\"#m5d29e222eb\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 25 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 19.1875 8.296875 \r\n",
       "L 53.609375 8.296875 \r\n",
       "L 53.609375 0 \r\n",
       "L 7.328125 0 \r\n",
       "L 7.328125 8.296875 \r\n",
       "Q 12.9375 14.109375 22.625 23.890625 \r\n",
       "Q 32.328125 33.6875 34.8125 36.53125 \r\n",
       "Q 39.546875 41.84375 41.421875 45.53125 \r\n",
       "Q 43.3125 49.21875 43.3125 52.78125 \r\n",
       "Q 43.3125 58.59375 39.234375 62.25 \r\n",
       "Q 35.15625 65.921875 28.609375 65.921875 \r\n",
       "Q 23.96875 65.921875 18.8125 64.3125 \r\n",
       "Q 13.671875 62.703125 7.8125 59.421875 \r\n",
       "L 7.8125 69.390625 \r\n",
       "Q 13.765625 71.78125 18.9375 73 \r\n",
       "Q 24.125 74.21875 28.421875 74.21875 \r\n",
       "Q 39.75 74.21875 46.484375 68.546875 \r\n",
       "Q 53.21875 62.890625 53.21875 53.421875 \r\n",
       "Q 53.21875 48.921875 51.53125 44.890625 \r\n",
       "Q 49.859375 40.875 45.40625 35.40625 \r\n",
       "Q 44.1875 33.984375 37.640625 27.21875 \r\n",
       "Q 31.109375 20.453125 19.1875 8.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-50\"/>\r\n",
       "       <path d=\"M 10.796875 72.90625 \r\n",
       "L 49.515625 72.90625 \r\n",
       "L 49.515625 64.59375 \r\n",
       "L 19.828125 64.59375 \r\n",
       "L 19.828125 46.734375 \r\n",
       "Q 21.96875 47.46875 24.109375 47.828125 \r\n",
       "Q 26.265625 48.1875 28.421875 48.1875 \r\n",
       "Q 40.625 48.1875 47.75 41.5 \r\n",
       "Q 54.890625 34.8125 54.890625 23.390625 \r\n",
       "Q 54.890625 11.625 47.5625 5.09375 \r\n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \r\n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \r\n",
       "Q 12.796875 0.140625 7.71875 1.703125 \r\n",
       "L 7.71875 11.625 \r\n",
       "Q 12.109375 9.234375 16.796875 8.0625 \r\n",
       "Q 21.484375 6.890625 26.703125 6.890625 \r\n",
       "Q 35.15625 6.890625 40.078125 11.328125 \r\n",
       "Q 45.015625 15.765625 45.015625 23.390625 \r\n",
       "Q 45.015625 31 40.078125 35.4375 \r\n",
       "Q 35.15625 39.890625 26.703125 39.890625 \r\n",
       "Q 22.75 39.890625 18.8125 39.015625 \r\n",
       "Q 14.890625 38.140625 10.796875 36.28125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-53\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(77.195445 239.238438)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"121.794582\" xlink:href=\"#m5d29e222eb\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 50 -->\r\n",
       "      <g transform=\"translate(115.432082 239.238438)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"160.03122\" xlink:href=\"#m5d29e222eb\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 75 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 8.203125 72.90625 \r\n",
       "L 55.078125 72.90625 \r\n",
       "L 55.078125 68.703125 \r\n",
       "L 28.609375 0 \r\n",
       "L 18.3125 0 \r\n",
       "L 43.21875 64.59375 \r\n",
       "L 8.203125 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-55\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(153.66872 239.238438)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-55\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"198.267858\" xlink:href=\"#m5d29e222eb\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 100 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 12.40625 8.296875 \r\n",
       "L 28.515625 8.296875 \r\n",
       "L 28.515625 63.921875 \r\n",
       "L 10.984375 60.40625 \r\n",
       "L 10.984375 69.390625 \r\n",
       "L 28.421875 72.90625 \r\n",
       "L 38.28125 72.90625 \r\n",
       "L 38.28125 8.296875 \r\n",
       "L 54.390625 8.296875 \r\n",
       "L 54.390625 0 \r\n",
       "L 12.40625 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-49\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(188.724108 239.238438)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_6\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"236.504495\" xlink:href=\"#m5d29e222eb\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 125 -->\r\n",
       "      <g transform=\"translate(226.960745 239.238438)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_7\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"274.741133\" xlink:href=\"#m5d29e222eb\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 150 -->\r\n",
       "      <g transform=\"translate(265.197383 239.238438)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_8\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"312.977771\" xlink:href=\"#m5d29e222eb\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 175 -->\r\n",
       "      <g transform=\"translate(303.434021 239.238438)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_9\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"351.214409\" xlink:href=\"#m5d29e222eb\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 200 -->\r\n",
       "      <g transform=\"translate(341.670659 239.238438)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m2933bfc3ad\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2933bfc3ad\" y=\"221.681906\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_10\">\r\n",
       "      <!-- 0.4 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 10.6875 12.40625 \r\n",
       "L 21 12.40625 \r\n",
       "L 21 0 \r\n",
       "L 10.6875 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-46\"/>\r\n",
       "       <path d=\"M 37.796875 64.3125 \r\n",
       "L 12.890625 25.390625 \r\n",
       "L 37.796875 25.390625 \r\n",
       "z\r\n",
       "M 35.203125 72.90625 \r\n",
       "L 47.609375 72.90625 \r\n",
       "L 47.609375 25.390625 \r\n",
       "L 58.015625 25.390625 \r\n",
       "L 58.015625 17.1875 \r\n",
       "L 47.609375 17.1875 \r\n",
       "L 47.609375 0 \r\n",
       "L 37.796875 0 \r\n",
       "L 37.796875 17.1875 \r\n",
       "L 4.890625 17.1875 \r\n",
       "L 4.890625 26.703125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(7.2 225.481125)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2933bfc3ad\" y=\"196.025424\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- 0.6 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 33.015625 40.375 \r\n",
       "Q 26.375 40.375 22.484375 35.828125 \r\n",
       "Q 18.609375 31.296875 18.609375 23.390625 \r\n",
       "Q 18.609375 15.53125 22.484375 10.953125 \r\n",
       "Q 26.375 6.390625 33.015625 6.390625 \r\n",
       "Q 39.65625 6.390625 43.53125 10.953125 \r\n",
       "Q 47.40625 15.53125 47.40625 23.390625 \r\n",
       "Q 47.40625 31.296875 43.53125 35.828125 \r\n",
       "Q 39.65625 40.375 33.015625 40.375 \r\n",
       "z\r\n",
       "M 52.59375 71.296875 \r\n",
       "L 52.59375 62.3125 \r\n",
       "Q 48.875 64.0625 45.09375 64.984375 \r\n",
       "Q 41.3125 65.921875 37.59375 65.921875 \r\n",
       "Q 27.828125 65.921875 22.671875 59.328125 \r\n",
       "Q 17.53125 52.734375 16.796875 39.40625 \r\n",
       "Q 19.671875 43.65625 24.015625 45.921875 \r\n",
       "Q 28.375 48.1875 33.59375 48.1875 \r\n",
       "Q 44.578125 48.1875 50.953125 41.515625 \r\n",
       "Q 57.328125 34.859375 57.328125 23.390625 \r\n",
       "Q 57.328125 12.15625 50.6875 5.359375 \r\n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \r\n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \r\n",
       "Q 6.984375 17.96875 6.984375 36.375 \r\n",
       "Q 6.984375 53.65625 15.1875 63.9375 \r\n",
       "Q 23.390625 74.21875 37.203125 74.21875 \r\n",
       "Q 40.921875 74.21875 44.703125 73.484375 \r\n",
       "Q 48.484375 72.75 52.59375 71.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-54\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(7.2 199.824643)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2933bfc3ad\" y=\"170.368943\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_12\">\r\n",
       "      <!-- 0.8 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 31.78125 34.625 \r\n",
       "Q 24.75 34.625 20.71875 30.859375 \r\n",
       "Q 16.703125 27.09375 16.703125 20.515625 \r\n",
       "Q 16.703125 13.921875 20.71875 10.15625 \r\n",
       "Q 24.75 6.390625 31.78125 6.390625 \r\n",
       "Q 38.8125 6.390625 42.859375 10.171875 \r\n",
       "Q 46.921875 13.96875 46.921875 20.515625 \r\n",
       "Q 46.921875 27.09375 42.890625 30.859375 \r\n",
       "Q 38.875 34.625 31.78125 34.625 \r\n",
       "z\r\n",
       "M 21.921875 38.8125 \r\n",
       "Q 15.578125 40.375 12.03125 44.71875 \r\n",
       "Q 8.5 49.078125 8.5 55.328125 \r\n",
       "Q 8.5 64.0625 14.71875 69.140625 \r\n",
       "Q 20.953125 74.21875 31.78125 74.21875 \r\n",
       "Q 42.671875 74.21875 48.875 69.140625 \r\n",
       "Q 55.078125 64.0625 55.078125 55.328125 \r\n",
       "Q 55.078125 49.078125 51.53125 44.71875 \r\n",
       "Q 48 40.375 41.703125 38.8125 \r\n",
       "Q 48.828125 37.15625 52.796875 32.3125 \r\n",
       "Q 56.78125 27.484375 56.78125 20.515625 \r\n",
       "Q 56.78125 9.90625 50.3125 4.234375 \r\n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.734375 -1.421875 13.25 4.234375 \r\n",
       "Q 6.78125 9.90625 6.78125 20.515625 \r\n",
       "Q 6.78125 27.484375 10.78125 32.3125 \r\n",
       "Q 14.796875 37.15625 21.921875 38.8125 \r\n",
       "z\r\n",
       "M 18.3125 54.390625 \r\n",
       "Q 18.3125 48.734375 21.84375 45.5625 \r\n",
       "Q 25.390625 42.390625 31.78125 42.390625 \r\n",
       "Q 38.140625 42.390625 41.71875 45.5625 \r\n",
       "Q 45.3125 48.734375 45.3125 54.390625 \r\n",
       "Q 45.3125 60.0625 41.71875 63.234375 \r\n",
       "Q 38.140625 66.40625 31.78125 66.40625 \r\n",
       "Q 25.390625 66.40625 21.84375 63.234375 \r\n",
       "Q 18.3125 60.0625 18.3125 54.390625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-56\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(7.2 174.168162)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_13\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2933bfc3ad\" y=\"144.712461\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_13\">\r\n",
       "      <!-- 1.0 -->\r\n",
       "      <g transform=\"translate(7.2 148.51168)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_14\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2933bfc3ad\" y=\"119.05598\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_14\">\r\n",
       "      <!-- 1.2 -->\r\n",
       "      <g transform=\"translate(7.2 122.855199)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_6\">\r\n",
       "     <g id=\"line2d_15\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2933bfc3ad\" y=\"93.399498\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_15\">\r\n",
       "      <!-- 1.4 -->\r\n",
       "      <g transform=\"translate(7.2 97.198717)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_7\">\r\n",
       "     <g id=\"line2d_16\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2933bfc3ad\" y=\"67.743017\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_16\">\r\n",
       "      <!-- 1.6 -->\r\n",
       "      <g transform=\"translate(7.2 71.542236)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_8\">\r\n",
       "     <g id=\"line2d_17\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2933bfc3ad\" y=\"42.086535\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_17\">\r\n",
       "      <!-- 1.8 -->\r\n",
       "      <g transform=\"translate(7.2 45.885754)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_9\">\r\n",
       "     <g id=\"line2d_18\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2933bfc3ad\" y=\"16.430054\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_18\">\r\n",
       "      <!-- 2.0 -->\r\n",
       "      <g transform=\"translate(7.2 20.229273)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_19\">\r\n",
       "    <path clip-path=\"url(#p5a69177695)\" d=\"M 45.321307 17.083636 \r\n",
       "L 46.850772 73.485868 \r\n",
       "L 48.380238 92.055546 \r\n",
       "L 49.909703 105.593948 \r\n",
       "L 51.439169 113.600799 \r\n",
       "L 52.968634 120.357413 \r\n",
       "L 54.4981 129.074037 \r\n",
       "L 56.027565 131.998518 \r\n",
       "L 59.086496 142.992697 \r\n",
       "L 60.615962 145.393845 \r\n",
       "L 62.145427 149.313089 \r\n",
       "L 63.674893 153.938577 \r\n",
       "L 65.204358 153.125539 \r\n",
       "L 66.733824 155.685258 \r\n",
       "L 68.263289 157.884782 \r\n",
       "L 69.792755 160.28599 \r\n",
       "L 71.32222 163.502681 \r\n",
       "L 72.851686 163.341246 \r\n",
       "L 74.381151 166.647724 \r\n",
       "L 75.910617 167.281361 \r\n",
       "L 77.440083 168.112287 \r\n",
       "L 78.969548 169.948577 \r\n",
       "L 80.499014 173.289249 \r\n",
       "L 82.028479 171.55541 \r\n",
       "L 83.557945 172.186175 \r\n",
       "L 85.08741 173.266663 \r\n",
       "L 86.616876 171.704162 \r\n",
       "L 88.146341 175.797232 \r\n",
       "L 89.675807 174.710434 \r\n",
       "L 91.205272 175.124708 \r\n",
       "L 92.734738 176.47957 \r\n",
       "L 94.264203 178.523075 \r\n",
       "L 95.793669 178.123116 \r\n",
       "L 97.323134 178.866772 \r\n",
       "L 98.8526 179.454098 \r\n",
       "L 100.382065 177.219994 \r\n",
       "L 101.911531 177.889467 \r\n",
       "L 103.440996 182.655225 \r\n",
       "L 104.970462 182.200934 \r\n",
       "L 106.499927 178.052761 \r\n",
       "L 108.029393 181.421842 \r\n",
       "L 109.558858 180.437536 \r\n",
       "L 111.088324 182.080825 \r\n",
       "L 112.617789 182.789397 \r\n",
       "L 114.147255 180.60947 \r\n",
       "L 115.67672 183.476798 \r\n",
       "L 117.206186 182.891843 \r\n",
       "L 118.735651 182.670143 \r\n",
       "L 120.265117 183.946026 \r\n",
       "L 121.794582 182.588837 \r\n",
       "L 123.324048 182.153774 \r\n",
       "L 124.853513 184.269493 \r\n",
       "L 126.382979 186.982509 \r\n",
       "L 127.912444 185.306755 \r\n",
       "L 129.44191 180.159625 \r\n",
       "L 130.971375 183.588096 \r\n",
       "L 132.500841 184.874233 \r\n",
       "L 134.030306 184.88146 \r\n",
       "L 135.559772 183.251542 \r\n",
       "L 137.089237 184.40676 \r\n",
       "L 138.618703 185.112826 \r\n",
       "L 140.148168 187.947348 \r\n",
       "L 141.677634 185.525208 \r\n",
       "L 143.207099 186.045068 \r\n",
       "L 144.736565 185.678738 \r\n",
       "L 146.26603 184.678419 \r\n",
       "L 149.324961 187.682454 \r\n",
       "L 150.854427 186.536348 \r\n",
       "L 152.383892 186.763084 \r\n",
       "L 153.913358 187.595634 \r\n",
       "L 155.442823 187.551074 \r\n",
       "L 156.972289 187.210117 \r\n",
       "L 158.501755 186.655555 \r\n",
       "L 160.03122 185.778141 \r\n",
       "L 161.560686 189.817363 \r\n",
       "L 163.090151 187.011022 \r\n",
       "L 164.619617 189.326985 \r\n",
       "L 166.149082 185.992342 \r\n",
       "L 167.678548 189.031854 \r\n",
       "L 169.208013 187.531849 \r\n",
       "L 170.737479 189.478689 \r\n",
       "L 172.266944 190.672528 \r\n",
       "L 173.79641 186.693682 \r\n",
       "L 175.325875 189.808825 \r\n",
       "L 176.855341 187.726702 \r\n",
       "L 178.384806 188.968809 \r\n",
       "L 179.914272 191.259315 \r\n",
       "L 181.443737 189.991965 \r\n",
       "L 182.973203 187.821534 \r\n",
       "L 184.502668 187.780934 \r\n",
       "L 186.032134 189.850134 \r\n",
       "L 187.561599 188.843649 \r\n",
       "L 189.091065 192.061076 \r\n",
       "L 190.62053 186.098308 \r\n",
       "L 192.149996 189.315308 \r\n",
       "L 193.679461 192.140472 \r\n",
       "L 195.208927 186.914733 \r\n",
       "L 196.738392 190.326467 \r\n",
       "L 198.267858 190.098682 \r\n",
       "L 199.797323 190.296237 \r\n",
       "L 201.326789 193.11037 \r\n",
       "L 202.856254 191.484452 \r\n",
       "L 205.915185 188.770929 \r\n",
       "L 207.444651 190.904086 \r\n",
       "L 208.974116 188.157871 \r\n",
       "L 210.503582 190.09065 \r\n",
       "L 212.033047 187.222151 \r\n",
       "L 213.562513 192.65524 \r\n",
       "L 215.091978 190.086395 \r\n",
       "L 216.621444 189.695313 \r\n",
       "L 218.150909 189.581677 \r\n",
       "L 219.680375 191.255701 \r\n",
       "L 222.739306 188.50132 \r\n",
       "L 224.268771 189.663933 \r\n",
       "L 225.798237 190.56982 \r\n",
       "L 227.327702 189.367075 \r\n",
       "L 228.857168 191.14207 \r\n",
       "L 230.386633 187.262287 \r\n",
       "L 231.916099 191.265075 \r\n",
       "L 233.445564 189.162646 \r\n",
       "L 234.97503 187.455832 \r\n",
       "L 236.504495 191.094386 \r\n",
       "L 238.033961 189.793284 \r\n",
       "L 239.563427 192.929624 \r\n",
       "L 241.092892 193.866685 \r\n",
       "L 242.622358 194.499124 \r\n",
       "L 244.151823 189.688634 \r\n",
       "L 245.681289 193.824295 \r\n",
       "L 247.210754 190.86904 \r\n",
       "L 248.74022 191.827109 \r\n",
       "L 250.269685 190.781404 \r\n",
       "L 251.799151 187.668362 \r\n",
       "L 253.328616 191.106832 \r\n",
       "L 254.858082 192.321897 \r\n",
       "L 256.387547 191.611551 \r\n",
       "L 259.446478 193.119453 \r\n",
       "L 260.975944 191.199061 \r\n",
       "L 262.505409 191.591018 \r\n",
       "L 264.034875 191.482654 \r\n",
       "L 265.56434 191.841692 \r\n",
       "L 267.093806 188.381742 \r\n",
       "L 268.623271 190.538452 \r\n",
       "L 270.152737 193.69996 \r\n",
       "L 271.682202 192.196875 \r\n",
       "L 274.741133 191.800922 \r\n",
       "L 276.270599 192.1424 \r\n",
       "L 277.800064 190.852772 \r\n",
       "L 279.32953 192.727907 \r\n",
       "L 280.858995 191.243788 \r\n",
       "L 282.388461 191.47099 \r\n",
       "L 283.917926 191.317426 \r\n",
       "L 285.447392 190.659951 \r\n",
       "L 286.976857 194.088213 \r\n",
       "L 288.506323 190.567572 \r\n",
       "L 290.035788 190.622679 \r\n",
       "L 291.565254 190.363885 \r\n",
       "L 293.094719 190.321367 \r\n",
       "L 294.624185 191.926419 \r\n",
       "L 296.15365 193.767984 \r\n",
       "L 297.683116 191.886362 \r\n",
       "L 299.212581 192.650772 \r\n",
       "L 300.742047 189.035201 \r\n",
       "L 302.271512 189.771178 \r\n",
       "L 303.800978 192.575002 \r\n",
       "L 305.330443 190.961116 \r\n",
       "L 306.859909 191.661294 \r\n",
       "L 308.389374 192.778841 \r\n",
       "L 309.91884 192.032041 \r\n",
       "L 311.448305 190.20545 \r\n",
       "L 312.977771 191.323846 \r\n",
       "L 314.507236 189.068703 \r\n",
       "L 316.036702 191.931102 \r\n",
       "L 317.566167 192.813335 \r\n",
       "L 319.095633 191.823488 \r\n",
       "L 320.625099 191.658382 \r\n",
       "L 322.154564 192.599068 \r\n",
       "L 323.68403 192.427976 \r\n",
       "L 325.213495 189.515643 \r\n",
       "L 326.742961 188.115834 \r\n",
       "L 328.272426 191.702543 \r\n",
       "L 329.801892 196.201764 \r\n",
       "L 331.331357 192.647963 \r\n",
       "L 332.860823 190.478525 \r\n",
       "L 334.390288 193.814088 \r\n",
       "L 335.919754 189.276416 \r\n",
       "L 337.449219 192.066597 \r\n",
       "L 338.978685 192.759474 \r\n",
       "L 340.50815 190.325997 \r\n",
       "L 342.037616 191.563334 \r\n",
       "L 343.567081 191.564318 \r\n",
       "L 345.096547 189.698806 \r\n",
       "L 346.626012 194.886026 \r\n",
       "L 349.684943 191.094738 \r\n",
       "L 349.684943 191.094738 \r\n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_20\">\r\n",
       "    <path clip-path=\"url(#p5a69177695)\" d=\"M 45.321307 78.228413 \r\n",
       "L 46.850772 103.72144 \r\n",
       "L 48.380238 118.204498 \r\n",
       "L 49.909703 129.655208 \r\n",
       "L 51.439169 138.105801 \r\n",
       "L 56.027565 158.205747 \r\n",
       "L 57.557031 163.05249 \r\n",
       "L 59.086496 167.464045 \r\n",
       "L 60.615962 171.009519 \r\n",
       "L 62.145427 175.871738 \r\n",
       "L 63.674893 178.005085 \r\n",
       "L 65.204358 179.385088 \r\n",
       "L 66.733824 181.693608 \r\n",
       "L 68.263289 183.738114 \r\n",
       "L 69.792755 184.955975 \r\n",
       "L 71.32222 188.819218 \r\n",
       "L 72.851686 188.482002 \r\n",
       "L 74.381151 189.638971 \r\n",
       "L 75.910617 192.477265 \r\n",
       "L 77.440083 192.381919 \r\n",
       "L 78.969548 193.372021 \r\n",
       "L 82.028479 197.042061 \r\n",
       "L 83.557945 197.486443 \r\n",
       "L 86.616876 199.462153 \r\n",
       "L 88.146341 200.174467 \r\n",
       "L 89.675807 200.528031 \r\n",
       "L 91.205272 200.493805 \r\n",
       "L 92.734738 201.95044 \r\n",
       "L 94.264203 203.935613 \r\n",
       "L 95.793669 203.228613 \r\n",
       "L 97.323134 202.944847 \r\n",
       "L 98.8526 204.273259 \r\n",
       "L 100.382065 202.463578 \r\n",
       "L 101.911531 202.944863 \r\n",
       "L 103.440996 204.830586 \r\n",
       "L 104.970462 206.069252 \r\n",
       "L 106.499927 204.96453 \r\n",
       "L 108.029393 204.429121 \r\n",
       "L 109.558858 206.058772 \r\n",
       "L 111.088324 206.283519 \r\n",
       "L 112.617789 206.367137 \r\n",
       "L 114.147255 206.037154 \r\n",
       "L 115.67672 206.235641 \r\n",
       "L 117.206186 207.356919 \r\n",
       "L 118.735651 207.687688 \r\n",
       "L 120.265117 208.262838 \r\n",
       "L 121.794582 207.783393 \r\n",
       "L 123.324048 208.441465 \r\n",
       "L 124.853513 208.291277 \r\n",
       "L 126.382979 208.344927 \r\n",
       "L 127.912444 209.096815 \r\n",
       "L 129.44191 209.462649 \r\n",
       "L 130.971375 208.262213 \r\n",
       "L 132.500841 208.190219 \r\n",
       "L 134.030306 207.421041 \r\n",
       "L 135.559772 207.468802 \r\n",
       "L 138.618703 211.538385 \r\n",
       "L 140.148168 209.803755 \r\n",
       "L 141.677634 209.520971 \r\n",
       "L 143.207099 209.966474 \r\n",
       "L 144.736565 209.111777 \r\n",
       "L 146.26603 209.569433 \r\n",
       "L 147.795496 211.70237 \r\n",
       "L 149.324961 209.416774 \r\n",
       "L 150.854427 211.106839 \r\n",
       "L 152.383892 211.518618 \r\n",
       "L 153.913358 211.6919 \r\n",
       "L 155.442823 210.84284 \r\n",
       "L 156.972289 211.813093 \r\n",
       "L 160.03122 211.796143 \r\n",
       "L 161.560686 210.574325 \r\n",
       "L 163.090151 210.599305 \r\n",
       "L 164.619617 211.549018 \r\n",
       "L 166.149082 209.945201 \r\n",
       "L 167.678548 211.686448 \r\n",
       "L 169.208013 212.766918 \r\n",
       "L 170.737479 211.853292 \r\n",
       "L 172.266944 213.118239 \r\n",
       "L 175.325875 211.170662 \r\n",
       "L 176.855341 211.062691 \r\n",
       "L 178.384806 211.792768 \r\n",
       "L 179.914272 211.57915 \r\n",
       "L 181.443737 213.499482 \r\n",
       "L 182.973203 212.432198 \r\n",
       "L 184.502668 212.043186 \r\n",
       "L 186.032134 210.614061 \r\n",
       "L 187.561599 211.225745 \r\n",
       "L 189.091065 212.567856 \r\n",
       "L 190.62053 209.184013 \r\n",
       "L 192.149996 211.092785 \r\n",
       "L 193.679461 212.667596 \r\n",
       "L 195.208927 210.152108 \r\n",
       "L 196.738392 211.188059 \r\n",
       "L 198.267858 210.884897 \r\n",
       "L 199.797323 212.441088 \r\n",
       "L 201.326789 211.701098 \r\n",
       "L 202.856254 212.678921 \r\n",
       "L 204.38572 212.437913 \r\n",
       "L 207.444651 212.555556 \r\n",
       "L 208.974116 211.57107 \r\n",
       "L 210.503582 211.696047 \r\n",
       "L 212.033047 209.661656 \r\n",
       "L 213.562513 213.672507 \r\n",
       "L 216.621444 211.487193 \r\n",
       "L 218.150909 210.686968 \r\n",
       "L 219.680375 212.018903 \r\n",
       "L 221.20984 210.703046 \r\n",
       "L 222.739306 211.87668 \r\n",
       "L 224.268771 211.636972 \r\n",
       "L 225.798237 213.316939 \r\n",
       "L 227.327702 210.794474 \r\n",
       "L 228.857168 211.469941 \r\n",
       "L 230.386633 211.23791 \r\n",
       "L 231.916099 212.691788 \r\n",
       "L 233.445564 212.222828 \r\n",
       "L 234.97503 212.998074 \r\n",
       "L 236.504495 209.005207 \r\n",
       "L 238.033961 212.924333 \r\n",
       "L 239.563427 211.876855 \r\n",
       "L 241.092892 212.005769 \r\n",
       "L 242.622358 212.988831 \r\n",
       "L 244.151823 209.225008 \r\n",
       "L 245.681289 211.235664 \r\n",
       "L 248.74022 212.66545 \r\n",
       "L 250.269685 212.125362 \r\n",
       "L 251.799151 213.293801 \r\n",
       "L 253.328616 211.485215 \r\n",
       "L 254.858082 210.746525 \r\n",
       "L 256.387547 212.513044 \r\n",
       "L 257.917013 213.766255 \r\n",
       "L 259.446478 211.940483 \r\n",
       "L 260.975944 214.345065 \r\n",
       "L 262.505409 212.349743 \r\n",
       "L 264.034875 210.959162 \r\n",
       "L 265.56434 213.723411 \r\n",
       "L 267.093806 211.023442 \r\n",
       "L 268.623271 213.135552 \r\n",
       "L 271.682202 212.233901 \r\n",
       "L 273.211668 212.112131 \r\n",
       "L 274.741133 214.004347 \r\n",
       "L 276.270599 212.367829 \r\n",
       "L 277.800064 213.84606 \r\n",
       "L 279.32953 214.279242 \r\n",
       "L 280.858995 213.826669 \r\n",
       "L 283.917926 211.871871 \r\n",
       "L 285.447392 212.590005 \r\n",
       "L 288.506323 211.929558 \r\n",
       "L 290.035788 210.009469 \r\n",
       "L 291.565254 209.849137 \r\n",
       "L 293.094719 212.79022 \r\n",
       "L 294.624185 213.605832 \r\n",
       "L 296.15365 213.505033 \r\n",
       "L 297.683116 211.995051 \r\n",
       "L 299.212581 213.142999 \r\n",
       "L 300.742047 214.756364 \r\n",
       "L 303.800978 213.367499 \r\n",
       "L 305.330443 212.363027 \r\n",
       "L 306.859909 213.612419 \r\n",
       "L 308.389374 211.649169 \r\n",
       "L 311.448305 214.754067 \r\n",
       "L 312.977771 214.263039 \r\n",
       "L 314.507236 214.025209 \r\n",
       "L 316.036702 214.029276 \r\n",
       "L 317.566167 213.339805 \r\n",
       "L 319.095633 211.827491 \r\n",
       "L 320.625099 213.665085 \r\n",
       "L 322.154564 213.286046 \r\n",
       "L 323.68403 212.30068 \r\n",
       "L 325.213495 212.487351 \r\n",
       "L 326.742961 212.290896 \r\n",
       "L 328.272426 211.876724 \r\n",
       "L 329.801892 213.79383 \r\n",
       "L 331.331357 213.125858 \r\n",
       "L 332.860823 213.129443 \r\n",
       "L 334.390288 212.946628 \r\n",
       "L 335.919754 211.573157 \r\n",
       "L 337.449219 211.452751 \r\n",
       "L 338.978685 212.585122 \r\n",
       "L 340.50815 212.674272 \r\n",
       "L 343.567081 213.283822 \r\n",
       "L 345.096547 211.914725 \r\n",
       "L 346.626012 211.588349 \r\n",
       "L 348.155478 213.734035 \r\n",
       "L 349.684943 211.61681 \r\n",
       "L 349.684943 211.61681 \r\n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 30.103125 224.64 \r\n",
       "L 30.103125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 364.903125 224.64 \r\n",
       "L 364.903125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 30.103125 224.64 \r\n",
       "L 364.903125 224.64 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 30.103125 7.2 \r\n",
       "L 364.903125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"legend_1\">\r\n",
       "    <g id=\"patch_7\">\r\n",
       "     <path d=\"M 263.957813 44.55625 \r\n",
       "L 357.903125 44.55625 \r\n",
       "Q 359.903125 44.55625 359.903125 42.55625 \r\n",
       "L 359.903125 14.2 \r\n",
       "Q 359.903125 12.2 357.903125 12.2 \r\n",
       "L 263.957813 12.2 \r\n",
       "Q 261.957813 12.2 261.957813 14.2 \r\n",
       "L 261.957813 42.55625 \r\n",
       "Q 261.957813 44.55625 263.957813 44.55625 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_21\">\r\n",
       "     <path d=\"M 265.957813 20.298437 \r\n",
       "L 285.957813 20.298437 \r\n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_22\"/>\r\n",
       "    <g id=\"text_19\">\r\n",
       "     <!-- Training loss -->\r\n",
       "     <defs>\r\n",
       "      <path d=\"M -0.296875 72.90625 \r\n",
       "L 61.375 72.90625 \r\n",
       "L 61.375 64.59375 \r\n",
       "L 35.5 64.59375 \r\n",
       "L 35.5 0 \r\n",
       "L 25.59375 0 \r\n",
       "L 25.59375 64.59375 \r\n",
       "L -0.296875 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-84\"/>\r\n",
       "      <path d=\"M 41.109375 46.296875 \r\n",
       "Q 39.59375 47.171875 37.8125 47.578125 \r\n",
       "Q 36.03125 48 33.890625 48 \r\n",
       "Q 26.265625 48 22.1875 43.046875 \r\n",
       "Q 18.109375 38.09375 18.109375 28.8125 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 20.953125 51.171875 25.484375 53.578125 \r\n",
       "Q 30.03125 56 36.53125 56 \r\n",
       "Q 37.453125 56 38.578125 55.875 \r\n",
       "Q 39.703125 55.765625 41.0625 55.515625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-114\"/>\r\n",
       "      <path d=\"M 34.28125 27.484375 \r\n",
       "Q 23.390625 27.484375 19.1875 25 \r\n",
       "Q 14.984375 22.515625 14.984375 16.5 \r\n",
       "Q 14.984375 11.71875 18.140625 8.90625 \r\n",
       "Q 21.296875 6.109375 26.703125 6.109375 \r\n",
       "Q 34.1875 6.109375 38.703125 11.40625 \r\n",
       "Q 43.21875 16.703125 43.21875 25.484375 \r\n",
       "L 43.21875 27.484375 \r\n",
       "z\r\n",
       "M 52.203125 31.203125 \r\n",
       "L 52.203125 0 \r\n",
       "L 43.21875 0 \r\n",
       "L 43.21875 8.296875 \r\n",
       "Q 40.140625 3.328125 35.546875 0.953125 \r\n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \r\n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \r\n",
       "Q 6 8.015625 6 15.921875 \r\n",
       "Q 6 25.140625 12.171875 29.828125 \r\n",
       "Q 18.359375 34.515625 30.609375 34.515625 \r\n",
       "L 43.21875 34.515625 \r\n",
       "L 43.21875 35.40625 \r\n",
       "Q 43.21875 41.609375 39.140625 45 \r\n",
       "Q 35.0625 48.390625 27.6875 48.390625 \r\n",
       "Q 23 48.390625 18.546875 47.265625 \r\n",
       "Q 14.109375 46.140625 10.015625 43.890625 \r\n",
       "L 10.015625 52.203125 \r\n",
       "Q 14.9375 54.109375 19.578125 55.046875 \r\n",
       "Q 24.21875 56 28.609375 56 \r\n",
       "Q 40.484375 56 46.34375 49.84375 \r\n",
       "Q 52.203125 43.703125 52.203125 31.203125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-97\"/>\r\n",
       "      <path d=\"M 9.421875 54.6875 \r\n",
       "L 18.40625 54.6875 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 64.59375 \r\n",
       "L 9.421875 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-105\"/>\r\n",
       "      <path d=\"M 54.890625 33.015625 \r\n",
       "L 54.890625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 45.90625 32.71875 \r\n",
       "Q 45.90625 40.484375 42.875 44.328125 \r\n",
       "Q 39.84375 48.1875 33.796875 48.1875 \r\n",
       "Q 26.515625 48.1875 22.3125 43.546875 \r\n",
       "Q 18.109375 38.921875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.34375 51.125 25.703125 53.5625 \r\n",
       "Q 30.078125 56 35.796875 56 \r\n",
       "Q 45.21875 56 50.046875 50.171875 \r\n",
       "Q 54.890625 44.34375 54.890625 33.015625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-110\"/>\r\n",
       "      <path d=\"M 45.40625 27.984375 \r\n",
       "Q 45.40625 37.75 41.375 43.109375 \r\n",
       "Q 37.359375 48.484375 30.078125 48.484375 \r\n",
       "Q 22.859375 48.484375 18.828125 43.109375 \r\n",
       "Q 14.796875 37.75 14.796875 27.984375 \r\n",
       "Q 14.796875 18.265625 18.828125 12.890625 \r\n",
       "Q 22.859375 7.515625 30.078125 7.515625 \r\n",
       "Q 37.359375 7.515625 41.375 12.890625 \r\n",
       "Q 45.40625 18.265625 45.40625 27.984375 \r\n",
       "z\r\n",
       "M 54.390625 6.78125 \r\n",
       "Q 54.390625 -7.171875 48.1875 -13.984375 \r\n",
       "Q 42 -20.796875 29.203125 -20.796875 \r\n",
       "Q 24.46875 -20.796875 20.265625 -20.09375 \r\n",
       "Q 16.0625 -19.390625 12.109375 -17.921875 \r\n",
       "L 12.109375 -9.1875 \r\n",
       "Q 16.0625 -11.328125 19.921875 -12.34375 \r\n",
       "Q 23.78125 -13.375 27.78125 -13.375 \r\n",
       "Q 36.625 -13.375 41.015625 -8.765625 \r\n",
       "Q 45.40625 -4.15625 45.40625 5.171875 \r\n",
       "L 45.40625 9.625 \r\n",
       "Q 42.625 4.78125 38.28125 2.390625 \r\n",
       "Q 33.9375 0 27.875 0 \r\n",
       "Q 17.828125 0 11.671875 7.65625 \r\n",
       "Q 5.515625 15.328125 5.515625 27.984375 \r\n",
       "Q 5.515625 40.671875 11.671875 48.328125 \r\n",
       "Q 17.828125 56 27.875 56 \r\n",
       "Q 33.9375 56 38.28125 53.609375 \r\n",
       "Q 42.625 51.21875 45.40625 46.390625 \r\n",
       "L 45.40625 54.6875 \r\n",
       "L 54.390625 54.6875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-103\"/>\r\n",
       "      <path id=\"DejaVuSans-32\"/>\r\n",
       "      <path d=\"M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-108\"/>\r\n",
       "      <path d=\"M 30.609375 48.390625 \r\n",
       "Q 23.390625 48.390625 19.1875 42.75 \r\n",
       "Q 14.984375 37.109375 14.984375 27.296875 \r\n",
       "Q 14.984375 17.484375 19.15625 11.84375 \r\n",
       "Q 23.34375 6.203125 30.609375 6.203125 \r\n",
       "Q 37.796875 6.203125 41.984375 11.859375 \r\n",
       "Q 46.1875 17.53125 46.1875 27.296875 \r\n",
       "Q 46.1875 37.015625 41.984375 42.703125 \r\n",
       "Q 37.796875 48.390625 30.609375 48.390625 \r\n",
       "z\r\n",
       "M 30.609375 56 \r\n",
       "Q 42.328125 56 49.015625 48.375 \r\n",
       "Q 55.71875 40.765625 55.71875 27.296875 \r\n",
       "Q 55.71875 13.875 49.015625 6.21875 \r\n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \r\n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \r\n",
       "Q 5.515625 13.875 5.515625 27.296875 \r\n",
       "Q 5.515625 40.765625 12.171875 48.375 \r\n",
       "Q 18.84375 56 30.609375 56 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-111\"/>\r\n",
       "      <path d=\"M 44.28125 53.078125 \r\n",
       "L 44.28125 44.578125 \r\n",
       "Q 40.484375 46.53125 36.375 47.5 \r\n",
       "Q 32.28125 48.484375 27.875 48.484375 \r\n",
       "Q 21.1875 48.484375 17.84375 46.4375 \r\n",
       "Q 14.5 44.390625 14.5 40.28125 \r\n",
       "Q 14.5 37.15625 16.890625 35.375 \r\n",
       "Q 19.28125 33.59375 26.515625 31.984375 \r\n",
       "L 29.59375 31.296875 \r\n",
       "Q 39.15625 29.25 43.1875 25.515625 \r\n",
       "Q 47.21875 21.78125 47.21875 15.09375 \r\n",
       "Q 47.21875 7.46875 41.1875 3.015625 \r\n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \r\n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \r\n",
       "Q 10.6875 0.296875 5.421875 2 \r\n",
       "L 5.421875 11.28125 \r\n",
       "Q 10.40625 8.6875 15.234375 7.390625 \r\n",
       "Q 20.0625 6.109375 24.8125 6.109375 \r\n",
       "Q 31.15625 6.109375 34.5625 8.28125 \r\n",
       "Q 37.984375 10.453125 37.984375 14.40625 \r\n",
       "Q 37.984375 18.0625 35.515625 20.015625 \r\n",
       "Q 33.0625 21.96875 24.703125 23.78125 \r\n",
       "L 21.578125 24.515625 \r\n",
       "Q 13.234375 26.265625 9.515625 29.90625 \r\n",
       "Q 5.8125 33.546875 5.8125 39.890625 \r\n",
       "Q 5.8125 47.609375 11.28125 51.796875 \r\n",
       "Q 16.75 56 26.8125 56 \r\n",
       "Q 31.78125 56 36.171875 55.265625 \r\n",
       "Q 40.578125 54.546875 44.28125 53.078125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-115\"/>\r\n",
       "     </defs>\r\n",
       "     <g transform=\"translate(293.957813 23.798437)scale(0.1 -0.1)\">\r\n",
       "      <use xlink:href=\"#DejaVuSans-84\"/>\r\n",
       "      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "      <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "      <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "      <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "      <use x=\"239.888672\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "      <use x=\"267.671875\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "      <use x=\"331.050781\" xlink:href=\"#DejaVuSans-103\"/>\r\n",
       "      <use x=\"394.527344\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      <use x=\"426.314453\" xlink:href=\"#DejaVuSans-108\"/>\r\n",
       "      <use x=\"454.097656\" xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "      <use x=\"515.279297\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "      <use x=\"567.378906\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_23\">\r\n",
       "     <path d=\"M 265.957813 34.976562 \r\n",
       "L 285.957813 34.976562 \r\n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_24\"/>\r\n",
       "    <g id=\"text_20\">\r\n",
       "     <!-- Test loss -->\r\n",
       "     <defs>\r\n",
       "      <path d=\"M 56.203125 29.59375 \r\n",
       "L 56.203125 25.203125 \r\n",
       "L 14.890625 25.203125 \r\n",
       "Q 15.484375 15.921875 20.484375 11.0625 \r\n",
       "Q 25.484375 6.203125 34.421875 6.203125 \r\n",
       "Q 39.59375 6.203125 44.453125 7.46875 \r\n",
       "Q 49.3125 8.734375 54.109375 11.28125 \r\n",
       "L 54.109375 2.78125 \r\n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \r\n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \r\n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \r\n",
       "Q 5.515625 13.8125 5.515625 26.8125 \r\n",
       "Q 5.515625 40.234375 12.765625 48.109375 \r\n",
       "Q 20.015625 56 32.328125 56 \r\n",
       "Q 43.359375 56 49.78125 48.890625 \r\n",
       "Q 56.203125 41.796875 56.203125 29.59375 \r\n",
       "z\r\n",
       "M 47.21875 32.234375 \r\n",
       "Q 47.125 39.59375 43.09375 43.984375 \r\n",
       "Q 39.0625 48.390625 32.421875 48.390625 \r\n",
       "Q 24.90625 48.390625 20.390625 44.140625 \r\n",
       "Q 15.875 39.890625 15.1875 32.171875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-101\"/>\r\n",
       "      <path d=\"M 18.3125 70.21875 \r\n",
       "L 18.3125 54.6875 \r\n",
       "L 36.8125 54.6875 \r\n",
       "L 36.8125 47.703125 \r\n",
       "L 18.3125 47.703125 \r\n",
       "L 18.3125 18.015625 \r\n",
       "Q 18.3125 11.328125 20.140625 9.421875 \r\n",
       "Q 21.96875 7.515625 27.59375 7.515625 \r\n",
       "L 36.8125 7.515625 \r\n",
       "L 36.8125 0 \r\n",
       "L 27.59375 0 \r\n",
       "Q 17.1875 0 13.234375 3.875 \r\n",
       "Q 9.28125 7.765625 9.28125 18.015625 \r\n",
       "L 9.28125 47.703125 \r\n",
       "L 2.6875 47.703125 \r\n",
       "L 2.6875 54.6875 \r\n",
       "L 9.28125 54.6875 \r\n",
       "L 9.28125 70.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-116\"/>\r\n",
       "     </defs>\r\n",
       "     <g transform=\"translate(293.957813 38.476562)scale(0.1 -0.1)\">\r\n",
       "      <use xlink:href=\"#DejaVuSans-84\"/>\r\n",
       "      <use x=\"44.083984\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"105.607422\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "      <use x=\"157.707031\" xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "      <use x=\"196.916016\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      <use x=\"228.703125\" xlink:href=\"#DejaVuSans-108\"/>\r\n",
       "      <use x=\"256.486328\" xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "      <use x=\"317.667969\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "      <use x=\"369.767578\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"p5a69177695\">\r\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(keras_history.history['loss'], label='Training loss')\n",
    "plt.plot(keras_history.history['val_loss'], color='red', label='Test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1B1b4YcoMoY"
   },
   "source": [
    "**We now urge you to tweak various hyperparamers, such as the learning rate,  dropout rate, regularization parameter, batch size, number of layers, number of neurons, etc. to get an idea of how the model performs with such changes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNvrOIEypT9v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "biJIIaHWpUCw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MHgbYB8QpUk5"
   },
   "source": [
    "Awesome! Hope you've gotten the gist of how to use Keras and how simple and straightforward it is to use."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KerasIntro",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('DeepLearning_Tensorflow': conda)",
   "language": "python",
   "name": "python_defaultSpec_1595521673045"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}